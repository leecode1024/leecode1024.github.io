<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">
<script>
    (function () {
        if ('') {
            if (prompt('请输入文章密码') !== '') {
                alert('密码错误！');
                if (history.length === 1) {
                    location.replace("http://leecode1024.github.io"); // 这里替换成你的首页
                } else {
                    history.back();
                }
            }
        }
    })();
</script>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Python,网络爬虫," />





  <link rel="alternate" href="/atom.xml" title="Lee" type="application/atom+xml" />






<meta name="description" content="网络爬虫什么是网络爬虫： 通俗理解：爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并数据抓取下来，然后使用一定的规则提取有价值的数据。 专业介绍：百度百科。">
<meta property="og:type" content="article">
<meta property="og:title" content="Python之网络爬虫">
<meta property="og:url" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/Python%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Lee">
<meta property="og:description" content="网络爬虫什么是网络爬虫： 通俗理解：爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并数据抓取下来，然后使用一定的规则提取有价值的数据。 专业介绍：百度百科。">
<meta property="og:image" content="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/1.png">
<meta property="og:image" content="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/2.png">
<meta property="og:image" content="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/3.png">
<meta property="og:image" content="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/4.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/scrapy_all.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/884863172-5985e0b48edf9.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/QQ%E6%88%AA%E5%9B%BE20171212213138.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/scrapy_all.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/scrapy-redis.png">
<meta property="og:image" content="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/assets/fenbushi.png">
<meta property="article:published_time" content="2020-06-04T11:48:18.000Z">
<meta property="article:modified_time" content="2020-06-07T01:10:00.919Z">
<meta property="article:author" content="李义">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="网络爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/Python之网络爬虫/"/>





  <title>Python之网络爬虫 | Lee</title>
  









<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Lee</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">捣鼓一个博客玩</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/leecode1024/leecode1024.github.io/2020/06/04/Python%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="李义">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Python之网络爬虫</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-04T19:48:18+08:00">
                2020-06-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2020-06-07T09:10:00+08:00">
                2020-06-07
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2020/06/04/Python%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" class="leancloud_visitors" data-flag-title="Python之网络爬虫">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  23.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  97
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="网络爬虫"><a href="#网络爬虫" class="headerlink" title="网络爬虫"></a>网络爬虫</h1><h1 id="什么是网络爬虫："><a href="#什么是网络爬虫：" class="headerlink" title="什么是网络爬虫："></a>什么是网络爬虫：</h1><ul>
<li>通俗理解：爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并数据抓取下来，然后使用一定的规则提取有价值的数据。</li>
<li>专业介绍：<a href="https://baike.baidu.com/item/网络爬虫/5162711?fr=aladdin" target="_blank" rel="noopener">百度百科</a>。</li>
</ul>
<a id="more"></a>

<h1 id="http协议和Chrome抓包工具"><a href="#http协议和Chrome抓包工具" class="headerlink" title="http协议和Chrome抓包工具"></a>http协议和Chrome抓包工具</h1><h2 id="什么是http和https协议："><a href="#什么是http和https协议：" class="headerlink" title="什么是http和https协议："></a>什么是http和https协议：</h2><p>HTTP协议：全称是<code>HyperText Transfer Protocol</code>，中文意思是超文本传输协议，是一种发布和接收HTML页面的方法。服务器端口号是<code>80</code>端口。 HTTPS协议：是HTTP协议的加密版本，在HTTP下加入了SSL层。服务器端口号是<code>443</code>端口。</p>
<h2 id="浏览器请求"><a href="#浏览器请求" class="headerlink" title="浏览器请求"></a>浏览器请求</h2><ol>
<li>当用户在浏览器的地址栏中输入一个URL并按回车键之后，浏览器会向HTTP服务器发送HTTP请求。HTTP请求主要分为“Get”和“Post”两种方法。</li>
<li>当我们在浏览器输入URL <a href="http://www.baidu.com" target="_blank" rel="noopener">http://www.baidu.com</a> 的时候，浏览器发送一个Request请求去获取 <a href="http://www.baidu.com" target="_blank" rel="noopener">http://www.baidu.com</a> 的html文件，服务器把Response文件对象发送回给浏览器。</li>
<li>浏览器分析Response中的 HTML，发现其中引用了很多其他文件，比如Images文件，CSS文件，JS文件。 浏览器会自动再次发送Request去获取图片，CSS文件，或者JS文件。</li>
<li>当所有的文件都下载成功后，网页会根据HTML语法结构，完整的显示出来了。</li>
</ol>
<h3 id="什么是URL"><a href="#什么是URL" class="headerlink" title="什么是URL"></a>什么是URL</h3><p><code>URL</code>是<code>Uniform Resource Locator</code>的简写，统一资源定位符。 一个<code>URL</code>由以下几部分组成：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scheme:<span class="regexp">//</span>host:port<span class="regexp">/path/</span>?query-string=xxx<span class="comment">#anchor</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>scheme</strong>：代表的是访问的协议，一般为<code>http</code>或者<code>https</code>以及<code>ftp</code>等。</li>
<li><strong>host</strong>：主机名，域名，比如<code>www.baidu.com</code>。</li>
<li><strong>port</strong>：端口号。当你访问一个网站的时候，浏览器默认使用80端口。</li>
<li><strong>path</strong>：查找路径。比如：<code>www.jianshu.com/trending/now</code>，后面的<code>trending/now</code>就是<code>path</code>。</li>
<li><strong>query-string</strong>：查询字符串，比如：<code>www.baidu.com/s?wd=python</code>，后面的<code>wd=python</code>就是查询字符串。</li>
<li><strong>anchor</strong>：锚点，后台一般不用管，前端用来做页面定位的。</li>
</ul>
<p>在浏览器中请求一个<code>url</code>，浏览器会对这个url进行一个编码。除英文字母，数字和部分符号外，其他的全部使用百分号+十六进制码值进行编码。</p>
<h3 id="常用的请求方法"><a href="#常用的请求方法" class="headerlink" title="常用的请求方法"></a>常用的请求方法</h3><p>这里介绍常用的get和post请求。</p>
<ul>
<li><code>get</code>请求：一般情况下，只从服务器获取数据下来，并不会对服务器资源产生任何影响的时候会使用<code>get</code>请求。</li>
<li><code>post</code>请求：向服务器发送数据（登录）、上传文件等，会对服务器资源产生影响的时候会使用<code>post</code>请求。 以上是在网站开发中常用的两种方法。并且一般情况下都会遵循使用的原则。但是有的网站和服务器为了做反爬虫机制，也经常会不按常理出牌，有可能一个应该使用<code>get</code>方法的请求就一定要改成<code>post</code>请求，这个要视情况而定。</li>
</ul>
<h3 id="请求头常见参数"><a href="#请求头常见参数" class="headerlink" title="请求头常见参数"></a>请求头常见参数</h3><p>在<code>http</code>协议中，向服务器发送一个请求，数据分为三部分，第一个是把数据放在url中，第二个是把数据放在<code>body</code>中（在<code>post</code>请求中），第三个就是把数据放在<code>head</code>中。这里介绍在网络爬虫中经常会用到的一些请求头参数：</p>
<ol>
<li><code>User-Agent</code>：浏览器名称。这个在网络爬虫中经常会被使用到。请求一个网页的时候，服务器通过这个参数就可以知道这个请求是由哪种浏览器发送的。如果我们是通过爬虫发送请求，那么我们的<code>User-Agent</code>就是<code>Python</code>，这对于那些有反爬虫机制的网站来说，可以轻易的判断你这个请求是爬虫。因此我们要经常设置这个值为一些浏览器的值，来伪装我们的爬虫。</li>
<li><code>Referer</code>：表明当前这个请求是从哪个<code>url</code>过来的。这个一般也可以用来做反爬虫技术。如果不是从指定页面过来的，那么就不做相关的响应。</li>
<li><code>Cookie</code>：<code>http</code>协议是无状态的。也就是同一个人发送了两次请求，服务器没有能力知道这两个请求是否来自同一个人。因此这时候就用<code>cookie</code>来做标识。一般如果想要做登录后才能访问的网站，那么就需要发送<code>cookie</code>信息了。</li>
</ol>
<h3 id="常见响应状态码"><a href="#常见响应状态码" class="headerlink" title="常见响应状态码"></a>常见响应状态码</h3><ol>
<li><code>200</code>：请求正常，服务器正常的返回数据。</li>
<li><code>301</code>：永久重定向。比如在访问<code>www.jingdong.com</code>的时候会重定向到<code>www.jd.com</code>。</li>
<li><code>302</code>：临时重定向。比如在访问一个需要登录的页面的时候，而此时没有登录，那么就会重定向到登录页面。</li>
<li><code>400</code>：请求的<code>url</code>在服务器上找不到。换句话说就是请求<code>url</code>错误。</li>
<li><code>403</code>：服务器拒绝访问，权限不够。</li>
<li><code>500</code>：服务器内部错误。可能是服务器出现<code>bug</code>了。</li>
</ol>
<h2 id="Chrome抓包工具："><a href="#Chrome抓包工具：" class="headerlink" title="Chrome抓包工具："></a>Chrome抓包工具：</h2><p><code>Chrome</code>浏览器是一个非常亲近开发者的浏览器。可以方便的查看网络请求以及发送的参数。对着网页<code>右键-&gt;检查</code>。然后就可以打开开发者选项。以下用图片来说明。</p>
<p><img src="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/1.png" alt=""></p>
<p><img src="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/2.png" alt=""></p>
<p><img src="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/3.png" alt=""></p>
<p><img src="https://leecode1024.oss-cn-qingdao.aliyuncs.com/pachong/4.png" alt=""></p>
<h1 id="urllib库"><a href="#urllib库" class="headerlink" title="urllib库"></a>urllib库</h1><p><code>urllib</code>库是<code>Python</code>中一个最基本的网络请求库。可以模拟浏览器的行为，向指定的服务器发送一个请求，并可以保存服务器返回的数据。</p>
<h2 id="urlopen"><a href="#urlopen" class="headerlink" title="urlopen"></a>urlopen</h2><p>在<code>Python3</code>的<code>urllib</code>库中，所有和网络请求相关的方法，都被集到<code>urllib.request</code>模块下面了，以先来看下<code>urlopen</code>函数基本的使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line">resp = request.urlopen(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(resp.read())</span><br></pre></td></tr></table></figure>

<p>实际上，使用浏览器访问百度，右键查看源代码。你会发现，跟我们刚才打印出来的数据是一模一样的。也就是说，上面的三行代码就已经帮我们把百度的首页的全部代码爬下来了。一个基本的url请求对应的python代码真的非常简单。<br>以下对<code>urlopen</code>函数的进行详细讲解：</p>
<ol>
<li><code>url</code>：请求的url。</li>
<li><code>data</code>：请求的<code>data</code>，如果设置了这个值，那么将变成<code>post</code>请求。</li>
<li>返回值：返回值是一个<code>http.client.HTTPResponse</code>对象，这个对象是一个类文件句柄对象。有<code>read(size)</code>、<code>readline</code>、<code>readlines</code>以及<code>getcode</code>等方法。</li>
</ol>
<h2 id="urlretrieve函数"><a href="#urlretrieve函数" class="headerlink" title="urlretrieve函数"></a>urlretrieve函数</h2><p>这个函数可以方便的将网页上的一个文件保存到本地。以下代码可以非常方便的将百度的首页下载到本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line">request.urlretrieve(<span class="string">'http://www.baidu.com/'</span>,<span class="string">'baidu.html'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="urlencode函数"><a href="#urlencode函数" class="headerlink" title="urlencode函数"></a>urlencode函数</h2><p>可以将经过编码后的url参数进行解码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">qs = <span class="string">"name=%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80&amp;greet=hello+world&amp;age=100"</span></span><br><span class="line">print(parse.parse_qs(qs))</span><br><span class="line"><span class="comment"># &#123;'name': ['爬虫基础'], 'greet': ['hello world'], 'age': ['100']&#125;</span></span><br></pre></td></tr></table></figure>

<h2 id="urlparse和urlsplit"><a href="#urlparse和urlsplit" class="headerlink" title="urlparse和urlsplit"></a>urlparse和urlsplit</h2><p>有时候拿到一个url，想要对这个url中的各个组成部分进行分割，那么这时候就可以使用<code>urlparse</code>或者是<code>urlsplit</code>来进行分割。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://www.baidu.com/s?username=zhiliao'</span></span><br><span class="line"></span><br><span class="line">result = parse.urlsplit(url)</span><br><span class="line"><span class="comment"># result = parse.urlparse(url)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'scheme:'</span>,result.scheme)</span><br><span class="line">print(<span class="string">'netloc:'</span>,result.netloc)</span><br><span class="line">print(<span class="string">'path:'</span>,result.path)</span><br><span class="line">print(<span class="string">'query:'</span>,result.query)</span><br><span class="line"><span class="comment">################################</span></span><br><span class="line">scheme: http</span><br><span class="line">netloc: www.baidu.com</span><br><span class="line">path: /s</span><br><span class="line">query: username=zhiliao</span><br></pre></td></tr></table></figure>

<p><code>urlparse</code>和<code>urlsplit</code>基本上是一模一样的。唯一不一样的地方是，<code>urlparse</code>里面多了一个<code>params</code>属性，而<code>urlsplit</code>没有这个<code>params</code>属性。比如有一个<code>url</code>为：<code>url = &#39;http://www.baidu.com/s;hello?wd=python&amp;username=abc#1&#39;</code>，<br>那么<code>urlparse</code>可以获取到<code>hello</code>，而<code>urlsplit</code>不可以获取到。<code>url</code>中的<code>params</code>也用得比较少。</p>
<h2 id="request-Request类"><a href="#request-Request类" class="headerlink" title="request.Request类"></a>request.Request类</h2><p>如果想要在请求的时候增加一些请求头，那么就必须使用<code>request.Request</code>类来实现。比如要增加一个<code>User-Agent</code>，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line"><span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">"http://www.baidu.com/"</span>,headers=headers)</span><br><span class="line">resp = request.urlopen(req)</span><br><span class="line">print(resp.read())</span><br></pre></td></tr></table></figure>

<h2 id="ProxyHandler处理器（代理设置）"><a href="#ProxyHandler处理器（代理设置）" class="headerlink" title="ProxyHandler处理器（代理设置）"></a>ProxyHandler处理器（代理设置）</h2><p>很多网站会检测某一段时间某个IP的访问次数(通过流量统计，系统日志等)，如果访问次数多的不像正常人，它会禁止这个IP的访问。<br>所以我们可以设置一些代理服务器，每隔一段时间换一个代理，就算IP被禁止，依然可以换个IP继续爬取。<br>urllib中通过ProxyHandler来设置使用代理服务器，下面代码说明如何使用自定义opener来使用代理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个是没有使用代理的</span></span><br><span class="line"><span class="comment"># resp = request.urlopen('http://httpbin.org/get')</span></span><br><span class="line"><span class="comment"># print(resp.read().decode("utf-8"))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个是使用了代理的</span></span><br><span class="line">handler = request.ProxyHandler(&#123;<span class="string">"http"</span>:<span class="string">"218.66.161.88:31769"</span>&#125;)</span><br><span class="line"></span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line">req = request.Request(<span class="string">"http://httpbin.org/ip"</span>)</span><br><span class="line">resp = opener.open(req)</span><br><span class="line">print(resp.read())</span><br></pre></td></tr></table></figure>

<p>常用的代理有：</p>
<ul>
<li>西刺免费代理IP：<a href="http://www.xicidaili.com/" target="_blank" rel="noopener">http://www.xicidaili.com/</a></li>
<li>快代理：<a href="http://www.kuaidaili.com/" target="_blank" rel="noopener">http://www.kuaidaili.com/</a></li>
<li>代理云：<a href="http://www.dailiyun.com/" target="_blank" rel="noopener">http://www.dailiyun.com/</a></li>
</ul>
<h1 id="什么是cookie"><a href="#什么是cookie" class="headerlink" title="什么是cookie"></a>什么是cookie</h1><p>在网站中，http请求是无状态的。也就是说即使第一次和服务器连接后并且登录成功后，第二次请求服务器依然不能知道当前请求是哪个用户。<code>cookie</code>的出现就是为了解决这个问题，第一次登录后服务器返回一些数据（cookie）给浏览器，然后浏览器保存在本地，当该用户发送第二次请求的时候，就会自动的把上次请求存储的<code>cookie</code>数据自动的携带给服务器，服务器通过浏览器携带的数据就能判断当前用户是哪个了。<code>cookie</code>存储的数据量有限，不同的浏览器有不同的存储大小，但一般不超过4KB。因此使用<code>cookie</code>只能存储一些小量的数据。</p>
<p><strong>cookie的格式</strong>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Set</span>-Cookie: <span class="keyword">NAME</span>=<span class="keyword">VALUE</span>；Expires/<span class="keyword">Max</span>-age=<span class="built_in">DATE</span>；<span class="keyword">Path</span>=<span class="keyword">PATH</span>；<span class="keyword">Domain</span>=DOMAIN_NAME；SECURE</span><br></pre></td></tr></table></figure>

<p>参数意义：</p>
<ul>
<li>NAME：cookie的名字。</li>
<li>VALUE：cookie的值。</li>
<li>Expires：cookie的过期时间。</li>
<li>Path：cookie作用的路径。</li>
<li>Domain：cookie作用的域名。</li>
<li>SECURE：是否只在https协议下起作用。</li>
</ul>
<h2 id="使用cookielib库和HTTPCookieProcessor模拟登录"><a href="#使用cookielib库和HTTPCookieProcessor模拟登录" class="headerlink" title="使用cookielib库和HTTPCookieProcessor模拟登录"></a>使用cookielib库和HTTPCookieProcessor模拟登录</h2><p>Cookie 是指网站服务器为了辨别用户身份和进行Session跟踪，而储存在用户浏览器上的文本文件，Cookie可以保持登录信息到用户下次与服务器的会话。<br>这里以人人网为例。人人网中，要访问某个人的主页，必须先登录才能访问，登录说白了就是要有cookie信息。那么如果我们想要用代码的方式访问，就必须要有正确的cookie信息才能访问。解决方案有两种，第一种是使用浏览器访问，然后将cookie信息复制下来，放到headers中。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Cookie'</span>: <span class="string">'anonymid=jacdwz2x-8bjldx; depovince=GW; _r01_=1; _ga=GA1.2.1455063316.1511436360; _gid=GA1.2.862627163.1511436360; wp=1; JSESSIONID=abczwY8ecd4xz8RJcyP-v; jebecookies=d4497791-9d41-4269-9e2b-3858d4989785|||||; ick_login=884e75d4-f361-4cff-94bb-81fe6c42b220; _de=EA5778F44555C091303554EBBEB4676C696BF75400CE19CC; p=61a3c7d0d4b2d1e991095353f83fa2141; first_login_flag=1; ln_uact=970138074@qq.com; ln_hurl=http://hdn.xnimg.cn/photos/hdn121/20170428/1700/main_nhiB_aebd0000854a1986.jpg; t=3dd84a3117737e819dd2c32f1cdb91d01; societyguester=3dd84a3117737e819dd2c32f1cdb91d01; id=443362311; xnsid=169efdc0; loginfrom=syshome; ch_id=10016; jebe_key=9c062f5a-4335-4a91-bf7a-970f8b86a64e%7Ca022c303305d1b2ab6b5089643e4b5de%7C1511449232839%7C1; wp_fold=0'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://www.renren.com/880151247/profile'</span></span><br><span class="line"></span><br><span class="line">req = request.Request(url,headers=headers)</span><br><span class="line">resp = request.urlopen(req)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'renren.html'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(resp.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>

<p>但是每次在访问需要cookie的页面都要从浏览器中复制cookie比较麻烦。在Python处理Cookie，一般是通过<code>http.cookiejar</code>模块和<code>urllib模块的HTTPCookieProcessor</code>处理器类一起使用。<code>http.cookiejar</code>模块主要作用是提供用于存储cookie的对象。而<code>HTTPCookieProcessor</code>处理器主要作用是处理这些cookie对象，并构建handler对象。</p>
<h2 id="http-cookiejar模块"><a href="#http-cookiejar模块" class="headerlink" title="http.cookiejar模块"></a>http.cookiejar模块</h2><p>该模块主要的类有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。这四个类的作用分别如下：</p>
<ol>
<li><strong>CookieJar</strong>：管理HTTP cookie值、存储HTTP请求生成的cookie、向传出的HTTP请求添加cookie的对象。整个cookie都存储在内存中，对CookieJar实例进行垃圾回收后cookie也将丢失。</li>
<li><strong>FileCookieJar</strong> (filename,delayload=None,policy=None)：从CookieJar派生而来，用来创建FileCookieJar实例，检索cookie信息并将cookie存储到文件中。filename是存储cookie的文件名。delayload为True时支持延迟访问访问文件，即只有在需要时才读取文件或在文件中存储数据。</li>
<li><strong>MozillaCookieJar</strong> (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与Mozilla浏览器 cookies.txt兼容的FileCookieJar实例。</li>
<li><strong>LWPCookieJar</strong> (filename,delayload=None,policy=None)：从FileCookieJar派生而来，创建与libwww-perl标准的 Set-Cookie3 文件格式兼容的FileCookieJar实例。</li>
</ol>
<h4 id="保存cookie到本地"><a href="#保存cookie到本地" class="headerlink" title="保存cookie到本地"></a>保存cookie到本地</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">保存cookie到本地，可以使用cookiejar的save方法，并且需要指定一个文件名：</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> MozillaCookieJar</span><br><span class="line"></span><br><span class="line">cookiejar = MozillaCookieJar(<span class="string">"cookie.txt"</span>)</span><br><span class="line">handler = request.HTTPCookieProcessor(cookiejar)</span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">'http://httpbin.org/cookies'</span>,headers=headers)</span><br><span class="line"></span><br><span class="line">resp = opener.open(req)</span><br><span class="line">print(resp.read())</span><br><span class="line">cookiejar.save(ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h4 id="从本地加载cookie"><a href="#从本地加载cookie" class="headerlink" title="从本地加载cookie"></a>从本地加载cookie</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">从本地加载cookie，需要使用cookiejar的load方法，并且也需要指定方法：</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> MozillaCookieJar</span><br><span class="line"></span><br><span class="line">cookiejar = MozillaCookieJar(<span class="string">"cookie.txt"</span>)</span><br><span class="line">cookiejar.load(ignore_expires=<span class="literal">True</span>,ignore_discard=<span class="literal">True</span>)</span><br><span class="line">handler = request.HTTPCookieProcessor(cookiejar)</span><br><span class="line">opener = request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">req = request.Request(<span class="string">'http://httpbin.org/cookies'</span>,headers=headers)</span><br><span class="line"></span><br><span class="line">resp = opener.open(req)</span><br><span class="line">print(resp.read())</span><br></pre></td></tr></table></figure>

<h1 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h1><p>虽然Python的标准库中 urllib模块已经包含了平常我们使用的大多数功能，但是它的 API 使用起来让人感觉不太好，而 Requests宣传是 “HTTP for Humans”，说明使用更简洁方便。</p>
<p><strong>安装和文档地址</strong>：</p>
<p>利用<code>pip</code>可以非常方便的安装：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> requests</span><br></pre></td></tr></table></figure>

<p>中文文档：<a href="http://docs.python-requests.org/zh_CN/latest/index.html" target="_blank" rel="noopener">http://docs.python-requests.org/zh_CN/latest/index.html</a><br>github地址：<a href="https://github.com/requests/requests">https://github.com/requests/requests</a></p>
<h2 id="发送GET请求"><a href="#发送GET请求" class="headerlink" title="发送GET请求"></a>发送GET请求</h2><ul>
<li>最简单的发送<code>get</code>请求就是通过<code>requests.get</code>来调用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/"</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>添加headers和查询参数</li>
</ul>
<p>如果想添加 headers，可以传入headers参数来增加请求头中的headers信息。如果要将参数放在url中传递，可以利用 params 参数。相关示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">kw = &#123;<span class="string">'wd'</span>:<span class="string">'中国'</span>&#125;</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</span></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/s"</span>, params = kw, headers = headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.text 返回的是Unicode格式的数据</span></span><br><span class="line">print(response.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.content返回的字节流数据</span></span><br><span class="line">print(response.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看完整url地址</span></span><br><span class="line">print(response.url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应头部字符编码</span></span><br><span class="line">print(response.encoding)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应码</span></span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>

<h2 id="发送POST请求"><a href="#发送POST请求" class="headerlink" title="发送POST请求"></a>发送POST请求</h2><ul>
<li>最基本的POST请求可以使用<code>post</code>方法</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(<span class="string">"http://www.baidu.com/"</span>,data=data)</span><br></pre></td></tr></table></figure>

<ul>
<li>传入data数据</li>
</ul>
<p>这时候就不要再使用<code>urlencode</code>进行编码了，直接传入一个字典进去就可以了。比如请求拉勾网的数据的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.lagou.com/jobs/positionAjax.json?city=%E6%B7%B1%E5%9C%B3&amp;needAddtionalResult=false&amp;isSchoolJob=0"</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Referer'</span>: <span class="string">'https://www.lagou.com/jobs/list_python?labelWords=&amp;fromSearch=true&amp;suginput='</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'first'</span>: <span class="string">'true'</span>,</span><br><span class="line">    <span class="string">'pn'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'kd'</span>: <span class="string">'python'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp = requests.post(url,headers=headers,data=data)</span><br><span class="line"><span class="comment"># 如果是json数据，直接可以调用json方法</span></span><br><span class="line">print(resp.json())</span><br></pre></td></tr></table></figure>

<h2 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h2><p>使用<code>requests</code>添加代理也非常简单，只要在请求的方法中（比如<code>get</code>或者<code>post</code>）传递<code>proxies</code>参数就可以了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://httpbin.org/get"</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">proxy = &#123;</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'171.14.209.180:27829'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp = requests.get(url,headers=headers,proxies=proxy)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'xx.html'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(resp.text)</span><br></pre></td></tr></table></figure>

<h2 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h2><p>如果在一个响应中包含了<code>cookie</code>，那么可以利用<code>cookies</code>属性拿到这个返回的<code>cookie</code>值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://www.renren.com/PLogin.do"</span></span><br><span class="line">data = &#123;<span class="string">"email"</span>:<span class="string">"970138074@qq.com"</span>,<span class="string">'password'</span>:<span class="string">"pythonspider"</span>&#125;</span><br><span class="line">resp = requests.get(<span class="string">'http://www.baidu.com/'</span>)</span><br><span class="line">print(resp.cookies)</span><br><span class="line">print(resp.cookies.get_dict())</span><br></pre></td></tr></table></figure>

<h2 id="session"><a href="#session" class="headerlink" title="session"></a>session</h2><p>之前使用<code>urllib</code>库，是可以使用<code>opener</code>发送多个请求，多个请求之间是可以共享<code>cookie</code>的。那么如果使用<code>requests</code>，也要达到共享<code>cookie</code>的目的，那么可以使用<code>requests</code>库给我们提供的<code>session</code>对象。注意，这里的<code>session</code>不是web开发中的那个session，这个地方只是一个会话的对象而已。还是以登录人人网为例，使用<code>requests</code>来实现。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://www.renren.com/PLogin.do"</span></span><br><span class="line">data = &#123;<span class="string">"email"</span>:<span class="string">"970138074@qq.com"</span>,<span class="string">'password'</span>:<span class="string">"pythonspider"</span>&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录</span></span><br><span class="line">session = requests.session()</span><br><span class="line">session.post(url,data=data,headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问大鹏个人中心</span></span><br><span class="line">resp = session.get(<span class="string">'http://www.renren.com/880151247/profile'</span>)</span><br><span class="line"></span><br><span class="line">print(resp.text)</span><br></pre></td></tr></table></figure>

<h1 id="XPath语法和lxml模块"><a href="#XPath语法和lxml模块" class="headerlink" title="XPath语法和lxml模块"></a>XPath语法和lxml模块</h1><h2 id="什么是XPath？"><a href="#什么是XPath？" class="headerlink" title="什么是XPath？"></a>什么是XPath？</h2><p>xpath（XML Path Language）是一门在XML和HTML文档中查找信息的语言，可用来在XML和HTML文档中对元素和属性进行遍历。</p>
<h2 id="XPath开发工具"><a href="#XPath开发工具" class="headerlink" title="XPath开发工具"></a>XPath开发工具</h2><ol>
<li>Chrome插件XPath Helper。</li>
<li>Firefox插件Try XPath。</li>
</ol>
<h2 id="XPath语法"><a href="#XPath语法" class="headerlink" title="XPath语法"></a>XPath语法</h2><h3 id="选取节点"><a href="#选取节点" class="headerlink" title="选取节点"></a>选取节点</h3><p>XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
<th>示例</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>nodename</td>
<td>选取此节点的所有子节点</td>
<td>bookstore</td>
<td>选取bookstore下所有的子节点</td>
</tr>
<tr>
<td>/</td>
<td>如果是在最前面，代表从根节点选取。否则选择某节点下的某个节点</td>
<td>/bookstore</td>
<td>选取根元素下所有的bookstore节点</td>
</tr>
<tr>
<td>//</td>
<td>从全局节点中选择节点，随便在哪个位置</td>
<td>//book</td>
<td>从全局节点中找到所有的book节点</td>
</tr>
<tr>
<td>@</td>
<td>选取某个节点的属性</td>
<td>//book[@price]</td>
<td>选择所有拥有price属性的book节点</td>
</tr>
<tr>
<td>.</td>
<td>当前节点</td>
<td>./a</td>
<td>选取当前节点下的a标签</td>
</tr>
</tbody></table>
<h3 id="谓语"><a href="#谓语" class="headerlink" title="谓语"></a>谓语</h3><p>谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。<br>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>/bookstore/book[1]</td>
<td>选取bookstore下的第一个子元素</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取bookstore下的倒数第二个book元素。</td>
</tr>
<tr>
<td>bookstore/book[position()&lt;3]</td>
<td>选取bookstore下前面两个子元素。</td>
</tr>
<tr>
<td>//book[@price]</td>
<td>选取拥有price属性的book元素</td>
</tr>
<tr>
<td>//book[@price=10]</td>
<td>选取所有属性price等于10的book元素</td>
</tr>
</tbody></table>
<h3 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h3><p>*表示通配符。</p>
<table>
<thead>
<tr>
<th align="left">通配符</th>
<th align="left">描述</th>
<th align="left">示例</th>
<th align="left">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">*</td>
<td align="left">匹配任意节点</td>
<td align="left">/bookstore/*</td>
<td align="left">选取bookstore下的所有子元素。</td>
</tr>
<tr>
<td align="left">@*</td>
<td align="left">匹配节点中的任何属性</td>
<td align="left">//book[@*]</td>
<td align="left">选取所有带有属性的book元素。</td>
</tr>
</tbody></table>
<h3 id="选取多个路径："><a href="#选取多个路径：" class="headerlink" title="选取多个路径："></a>选取多个路径：</h3><p>通过在路径表达式中使用“|”运算符，可以选取若干个路径。<br>示例如下：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">//</span>bookstore<span class="regexp">/book | /</span><span class="regexp">/book/</span>title</span><br><span class="line"><span class="comment"># 选取所有book元素以及book元素下所有的title元素</span></span><br></pre></td></tr></table></figure>

<h2 id="lxml库"><a href="#lxml库" class="headerlink" title="lxml库"></a>lxml库</h2><p>lxml 是 一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。</p>
<p>lxml和正则一样，也是用 C 实现的，是一款高性能的 Python HTML/XML 解析器，我们可以利用之前学习的XPath语法，来快速的定位特定元素以及节点信息。</p>
<p>lxml python 官方文档：<a href="http://lxml.de/index.html" target="_blank" rel="noopener">http://lxml.de/index.html</a></p>
<p>需要安装C语言库，可使用 pip 安装：pip install lxml</p>
<h3 id="基本使用："><a href="#基本使用：" class="headerlink" title="基本使用："></a>基本使用：</h3><p>我们可以利用他来解析HTML代码，并且在解析HTML代码的时候，如果HTML代码不规范，他会自动的进行补全。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 lxml 的 etree 库</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree </span><br><span class="line"></span><br><span class="line">text = <span class="string">'''</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt; # 注意，此处缺少一个 &lt;/li&gt; 闭合标签</span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#利用etree.HTML，将字符串解析为HTML文档</span></span><br><span class="line">html = etree.HTML(text) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 按字符串序列化HTML文档</span></span><br><span class="line">result = etree.tostring(html) </span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>

<p>输入结果如下：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link1.html"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-inactive"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>可以看到。lxml会自动修改HTML代码。例子中不仅补全了li标签，还添加了body，html标签。</p>
<h3 id="从文件中读取html代码："><a href="#从文件中读取html代码：" class="headerlink" title="从文件中读取html代码："></a>从文件中读取html代码：</h3><p>除了直接使用字符串进行解析，lxml还支持从文件中读取内容。我们新建一个hello.html文件：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hello.html --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link1.html"</span>&gt;</span>first item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link2.html"</span>&gt;</span>second item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-inactive"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link3.html"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"bold"</span>&gt;</span>third item<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-1"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link4.html"</span>&gt;</span>fourth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"item-0"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"link5.html"</span>&gt;</span>fifth item<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>然后利用<code>etree.parse()</code>方法来读取文件。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取外部文件 hello.html</span></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = etree.tostring(html, pretty_print=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>

<p>输入结果和之前是相同的。</p>
<h3 id="在lxml中使用XPath语法："><a href="#在lxml中使用XPath语法：" class="headerlink" title="在lxml中使用XPath语法："></a>在lxml中使用XPath语法：</h3><ol>
<li><p>获取所有li标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line"><span class="keyword">print</span> type(html)  <span class="comment"># 显示etree.parse() 返回类型</span></span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">'//li'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)  <span class="comment"># 打印&lt;li&gt;标签的元素集合</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取所有li元素下的所有class属性的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/@class'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取li标签下href为<code>www.baidu.com</code>的a标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/a[@href="www.baidu.com"]'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取li标签下所有span标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">   </span><br><span class="line"><span class="comment">#result = html.xpath('//li/span')</span></span><br><span class="line"><span class="comment">#注意这么写是不对的：</span></span><br><span class="line"><span class="comment">#因为 / 是用来获取子元素的，而 &lt;span&gt; 并不是 &lt;li&gt; 的子元素，所以，要用双斜杠</span></span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">'//li//span'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取li标签下的a标签里的所有class：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/a//@class'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取最后一个li的a的href属性对应的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">   </span><br><span class="line">result = html.xpath(<span class="string">'//li[last()]/a/@href'</span>)</span><br><span class="line"><span class="comment"># 谓语 [last()] 可以找到最后一个元素</span></span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取倒数第二个li元素的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li[last()-1]/a'</span>)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># text 方法可以获取元素内容</span></span><br><span class="line">print(result[<span class="number">0</span>].text)</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取倒数第二个li元素的内容的第二种方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">   </span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li[last()-1]/a/text()'</span>)</span><br><span class="line">   </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="爬取德州学院官网上的校报图片"><a href="#爬取德州学院官网上的校报图片" class="headerlink" title="爬取德州学院官网上的校报图片"></a>爬取德州学院官网上的校报图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36"</span></span><br><span class="line">        &#125;</span><br><span class="line">count=<span class="number">1</span></span><br><span class="line">xpath=<span class="string">'//div[@class="huigu"]//a/img/@src'</span></span><br><span class="line">url=<span class="string">"http://dzu.cuepa.cn/oldrelease.php"</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getResponse</span><span class="params">(url,headers)</span>:</span></span><br><span class="line">    response = requests.get(</span><br><span class="line">        url=url,</span><br><span class="line">        headers=headers</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forListSave</span><span class="params">(img_list,count,index)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        count_str=str(count)</span><br><span class="line">        imgCount = str(index)+<span class="string">"_"</span>+str(count_str) + <span class="string">"_img.jpg"</span></span><br><span class="line">        img_url = img</span><br><span class="line">        img_response = getResponse(img_url,headers)</span><br><span class="line">        print(<span class="string">"正在下载第"</span>+str(index)+<span class="string">"页，第"</span>+count_str+<span class="string">"张图片--"</span>+imgCount+<span class="string">"--url："</span>+img_url)</span><br><span class="line">        fp = open(imgCount, <span class="string">"wb"</span>)</span><br><span class="line">        fp.write(img_response.content)</span><br><span class="line">        fp.close()</span><br><span class="line">        print(<span class="string">"下载完成"</span>)</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line"><span class="comment">#-------------调用-----------</span></span><br><span class="line">response = getResponse(url,headers)</span><br><span class="line">eroot = etree.HTML(response.text)</span><br><span class="line">img_list = eroot.xpath(xpath)</span><br><span class="line">index = <span class="number">1</span></span><br><span class="line">forListSave(img_list,count,index)</span><br><span class="line">index = index+<span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> index &lt;= <span class="number">25</span>:</span><br><span class="line">    newUrl=url+<span class="string">"?page="</span>+str(index)</span><br><span class="line">    response = getResponse(newUrl, headers)</span><br><span class="line">    eroot = etree.HTML(response.text)</span><br><span class="line">    img_list = eroot.xpath(xpath)</span><br><span class="line">    forListSave(img_list,count,index)</span><br><span class="line">    index=index+<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h1 id="BeautifulSoup4库"><a href="#BeautifulSoup4库" class="headerlink" title="BeautifulSoup4库"></a>BeautifulSoup4库</h1><p>和 lxml 一样，Beautiful Soup 也是一个HTML/XML的解析器，主要的功能也是如何解析和提取 HTML/XML 数据。<br>lxml 只会局部遍历，而Beautiful Soup 是基于HTML DOM（Document Object Model）的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。<br>BeautifulSoup 用来解析 HTML 比较简单，API非常人性化，支持CSS选择器、Python标准库中的HTML解析器，也支持 lxml 的 XML解析器。<br>Beautiful Soup 3 目前已经停止开发，推荐现在的项目使用Beautiful Soup 4。</p>
<h2 id="安装和文档："><a href="#安装和文档：" class="headerlink" title="安装和文档："></a>安装和文档：</h2><ol>
<li>安装：<code>pip install bs4</code>。</li>
<li>中文文档：<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html</a></li>
</ol>
<h2 id="几大解析工具对比："><a href="#几大解析工具对比：" class="headerlink" title="几大解析工具对比："></a>几大解析工具对比：</h2><table>
<thead>
<tr>
<th>解析工具</th>
<th>解析速度</th>
<th>使用难度</th>
</tr>
</thead>
<tbody><tr>
<td>BeautifulSoup</td>
<td>最慢</td>
<td>最简单</td>
</tr>
<tr>
<td>lxml</td>
<td>快</td>
<td>简单</td>
</tr>
<tr>
<td>正则</td>
<td>最快</td>
<td>最难</td>
</tr>
</tbody></table>
<h2 id="简单使用："><a href="#简单使用：" class="headerlink" title="简单使用："></a>简单使用：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建 Beautiful Soup 对象</span></span><br><span class="line"><span class="comment"># 使用lxml来进行解析</span></span><br><span class="line">soup = BeautifulSoup(html,<span class="string">"lxml"</span>)</span><br><span class="line"></span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>

<h2 id="四个常用的对象："><a href="#四个常用的对象：" class="headerlink" title="四个常用的对象："></a>四个常用的对象：</h2><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种:</p>
<ol>
<li>Tag</li>
<li>NavigatableString</li>
<li>BeautifulSoup</li>
<li>Comment</li>
</ol>
<h3 id="1-Tag："><a href="#1-Tag：" class="headerlink" title="1. Tag："></a>1. Tag：</h3><p>Tag 通俗点讲就是 HTML 中的一个个标签。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建 Beautiful Soup 对象</span></span><br><span class="line">soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(soup.title)</span><br><span class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br><span class="line"></span><br><span class="line">print(soup.head)</span><br><span class="line"><span class="comment"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"></span><br><span class="line">print(soup.a)</span><br><span class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line">print(soup.p)</span><br><span class="line"><span class="comment"># &lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"></span><br><span class="line">print(type(soup.p))</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">结果：</span><br><span class="line">&lt;title&gt;The Dormous<span class="string">e's story&lt;/title&gt;</span></span><br><span class="line"><span class="string">&lt;head&gt;&lt;title&gt;The Dormouse'</span>s story&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;a <span class="keyword">class</span>="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!<span class="comment">-- Elsie --&gt;&lt;/a&gt;</span></span><br><span class="line">&lt;p <span class="keyword">class</span>="title" <span class="type">name</span>="dromouse"&gt;&lt;b&gt;The Dormous<span class="string">e's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;class '</span>bs4.element.Tag<span class="string">'&gt;</span></span><br></pre></td></tr></table></figure>

<p>我们可以利用 soup 加标签名轻松地获取这些标签的内容，这些对象的类型是bs4.element.Tag。但是注意，它查找的是在所有内容中的<strong>第一个符合要求的标签</strong>。如果要查询所有的标签，后面会进行介绍。<br>对于Tag，它有两个重要的属性，分别是<strong>name和attrs。</strong>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.name</span><br><span class="line"><span class="comment"># [document] #soup 对象本身比较特殊，它的 name 即为 [document]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.head.name</span><br><span class="line"><span class="comment"># head #对于其他内部标签，输出的值便为标签本身的名称</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.p.attrs</span><br><span class="line"><span class="comment"># &#123;'class': ['title'], 'name': 'dromouse'&#125;</span></span><br><span class="line"><span class="comment"># 在这里，我们把 p 标签的所有属性打印输出了出来，得到的类型是一个字典。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.p[<span class="string">'class'</span>] <span class="comment"># soup.p.get('class')</span></span><br><span class="line"><span class="comment"># ['title'] #还可以利用get方法，传入属性的名称，二者是等价的</span></span><br><span class="line"></span><br><span class="line">soup.p[<span class="string">'class'</span>] = <span class="string">"newClass"</span></span><br><span class="line"><span class="keyword">print</span> soup.p <span class="comment"># 可以对这些属性和内容等等进行修改</span></span><br><span class="line"><span class="comment"># &lt;p class="newClass" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-NavigableString："><a href="#2-NavigableString：" class="headerlink" title="2. NavigableString："></a>2. NavigableString：</h3><p>如果拿到标签后，还想获取标签中的内容。那么可以通过<code>tag.string</code>获取标签中的文字。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.p.string</span><br><span class="line"><span class="comment"># The Dormouse's story</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(soup.p.string)</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.NavigableString'&gt;thon</span></span><br></pre></td></tr></table></figure>

<h3 id="3-BeautifulSoup："><a href="#3-BeautifulSoup：" class="headerlink" title="3. BeautifulSoup："></a>3. BeautifulSoup：</h3><p>BeautifulSoup 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法.<br>因为 BeautifulSoup 对象并不是真正的HTML或XML的tag,所以它没有name和attribute属性.但有时查看它的 .name 属性是很方便的,所以 BeautifulSoup 对象包含了一个值为 “[document]” 的特殊属性 .name</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup.name</span><br><span class="line"><span class="comment"># '[document]'</span></span><br></pre></td></tr></table></figure>

<h3 id="4-Comment："><a href="#4-Comment：" class="headerlink" title="4. Comment："></a>4. Comment：</h3><p>Tag , NavigableString , BeautifulSoup 几乎覆盖了html和xml中的所有内容,但是还有一些特殊对象.容易让人担心的内容是文档的注释部分:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">markup = <span class="string">"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;"</span></span><br><span class="line">soup = BeautifulSoup(markup)</span><br><span class="line">comment = soup.b.string</span><br><span class="line">type(comment)</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>

<p>Comment 对象是一个特殊类型的 NavigableString 对象:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">comment</span><br><span class="line"><span class="comment"># 'Hey, buddy. Want to buy a used parser'</span></span><br></pre></td></tr></table></figure>

<h2 id="遍历文档树："><a href="#遍历文档树：" class="headerlink" title="遍历文档树："></a>遍历文档树：</h2><h3 id="1-contents和children："><a href="#1-contents和children：" class="headerlink" title="1. contents和children："></a>1. contents和children：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(html_doc,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">head_tag = soup.head</span><br><span class="line"><span class="comment"># 返回所有子节点的列表</span></span><br><span class="line">print(head_tag.contents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回所有子节点的迭代器</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> head_tag.children:</span><br><span class="line">    print(child)</span><br></pre></td></tr></table></figure>

<h3 id="2-strings-和-stripped-strings"><a href="#2-strings-和-stripped-strings" class="headerlink" title="2. strings 和 stripped_strings"></a>2. strings 和 stripped_strings</h3><p>如果tag中包含多个字符串 [2] ,可以使用 .strings 来循环获取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> string <span class="keyword">in</span> soup.strings:</span><br><span class="line">    print(repr(string))</span><br><span class="line">    <span class="comment"># u"The Dormouse's story"</span></span><br><span class="line">    <span class="comment"># u'\n\n'</span></span><br><span class="line">    <span class="comment"># u"The Dormouse's story"</span></span><br><span class="line">    <span class="comment"># u'\n\n'</span></span><br><span class="line">    <span class="comment"># u'Once upon a time there were three little sisters; and their names were\n'</span></span><br><span class="line">    <span class="comment"># u'Elsie'</span></span><br><span class="line">    <span class="comment"># u',\n'</span></span><br><span class="line">    <span class="comment"># u'Lacie'</span></span><br><span class="line">    <span class="comment"># u' and\n'</span></span><br><span class="line">    <span class="comment"># u'Tillie'</span></span><br><span class="line">    <span class="comment"># u';\nand they lived at the bottom of a well.'</span></span><br><span class="line">    <span class="comment"># u'\n\n'</span></span><br><span class="line">    <span class="comment"># u'...'</span></span><br><span class="line">    <span class="comment"># u'\n'</span></span><br></pre></td></tr></table></figure>

<p>输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> string <span class="keyword">in</span> soup.stripped_strings:</span><br><span class="line">    print(repr(string))</span><br><span class="line">    <span class="comment"># u"The Dormouse's story"</span></span><br><span class="line">    <span class="comment"># u"The Dormouse's story"</span></span><br><span class="line">    <span class="comment"># u'Once upon a time there were three little sisters; and their names were'</span></span><br><span class="line">    <span class="comment"># u'Elsie'</span></span><br><span class="line">    <span class="comment"># u','</span></span><br><span class="line">    <span class="comment"># u'Lacie'</span></span><br><span class="line">    <span class="comment"># u'and'</span></span><br><span class="line">    <span class="comment"># u'Tillie'</span></span><br><span class="line">    <span class="comment"># u';\nand they lived at the bottom of a well.'</span></span><br><span class="line">    <span class="comment"># u'...'</span></span><br></pre></td></tr></table></figure>

<h2 id="搜索文档树："><a href="#搜索文档树：" class="headerlink" title="搜索文档树："></a>搜索文档树：</h2><h3 id="1-find和find-all方法："><a href="#1-find和find-all方法：" class="headerlink" title="1. find和find_all方法："></a>1. find和find_all方法：</h3><p>搜索文档树，一般用得比较多的就是两个方法，一个是<code>find</code>，一个是<code>find_all</code>。<code>find</code>方法是找到第一个满足条件的标签后就立即返回，只返回一个元素。<code>find_all</code>方法是把所有满足条件的标签都选到，然后返回回去。使用这两个方法，最常用的用法是出入<code>name</code>以及<code>attr</code>参数找出符合要求的标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">"a"</span>,attrs=&#123;<span class="string">"id"</span>:<span class="string">"link2"</span>&#125;)</span><br></pre></td></tr></table></figure>

<p>或者是直接传入属性的的名字作为关键字参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">"a"</span>,id=<span class="string">'link2'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-select方法："><a href="#2-select方法：" class="headerlink" title="2. select方法："></a>2. select方法：</h3><p>使用以上方法可以方便的找出元素。但有时候使用<code>css</code>选择器的方式可以更加的方便。使用<code>css</code>选择器的语法，应该使用<code>select</code>方法。以下列出几种常用的<code>css</code>选择器方法：</p>
<h4 id="（1）通过标签名查找："><a href="#（1）通过标签名查找：" class="headerlink" title="（1）通过标签名查找："></a>（1）通过标签名查找：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">'a'</span>))</span><br></pre></td></tr></table></figure>

<h4 id="（2）通过类名查找："><a href="#（2）通过类名查找：" class="headerlink" title="（2）通过类名查找："></a>（2）通过类名查找：</h4><p>通过类名，则应该在类的前面加一个<code>.</code>。比如要查找<code>class=sister</code>的标签。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">'.sister'</span>))</span><br></pre></td></tr></table></figure>

<h4 id="（3）通过id查找："><a href="#（3）通过id查找：" class="headerlink" title="（3）通过id查找："></a>（3）通过id查找：</h4><p>通过id查找，应该在id的名字前面加一个＃号。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">"#link1"</span>))</span><br></pre></td></tr></table></figure>

<h4 id="（4）组合查找："><a href="#（4）组合查找：" class="headerlink" title="（4）组合查找："></a>（4）组合查找：</h4><p>组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">"p #link1"</span>))</span><br></pre></td></tr></table></figure>

<p>直接子标签查找，则使用 &gt; 分隔：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">"head &gt; title"</span>))</span><br></pre></td></tr></table></figure>

<h4 id="（5）通过属性查找："><a href="#（5）通过属性查找：" class="headerlink" title="（5）通过属性查找："></a>（5）通过属性查找：</h4><p>查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.select(<span class="string">'a[href="http://example.com/elsie"]'</span>))</span><br></pre></td></tr></table></figure>

<h4 id="（6）获取内容"><a href="#（6）获取内容" class="headerlink" title="（6）获取内容"></a>（6）获取内容</h4><p>以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="keyword">print</span> type(soup.select(<span class="string">'title'</span>))</span><br><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'title'</span>)[<span class="number">0</span>].get_text()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> soup.select(<span class="string">'title'</span>):</span><br><span class="line">    <span class="keyword">print</span> title.get_text()</span><br></pre></td></tr></table></figure>

<h1 id="正则表达式和re模块："><a href="#正则表达式和re模块：" class="headerlink" title="正则表达式和re模块："></a>正则表达式和re模块：</h1><h2 id="什么是正则表达式："><a href="#什么是正则表达式：" class="headerlink" title="什么是正则表达式："></a>什么是正则表达式：</h2><p>通俗理解：按照一定的规则，从某个字符串中匹配出想要的数据。这个规则就是正则表达式。<br>标准答案：<a href="https://baike.baidu.com/item/正则表达式/1700215?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/正则表达式/1700215?fr=aladdin</a></p>
<h2 id="一个段子："><a href="#一个段子：" class="headerlink" title="一个段子："></a>一个段子：</h2><p>世界是分为两种人，一种是懂正则表达式的，一种是不懂正则表达式的。</p>
<h2 id="正则表达式常用匹配规则："><a href="#正则表达式常用匹配规则：" class="headerlink" title="正则表达式常用匹配规则："></a>正则表达式常用匹配规则：</h2><h3 id="匹配某个字符串："><a href="#匹配某个字符串：" class="headerlink" title="匹配某个字符串："></a>匹配某个字符串：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'hello'</span></span><br><span class="line">ret = re.match(<span class="string">'he'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; he</span><br></pre></td></tr></table></figure>

<p>以上便可以在<code>hello</code>中，匹配出<code>he</code>。</p>
<h3 id="点（-）匹配任意的字符："><a href="#点（-）匹配任意的字符：" class="headerlink" title="点（.）匹配任意的字符："></a>点（.）匹配任意的字符：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"ab"</span></span><br><span class="line">ret = re.match(<span class="string">'.'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; a</span><br></pre></td></tr></table></figure>

<p>但是点（.）不能匹配不到换行符。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"ab"</span></span><br><span class="line">ret = re.match(<span class="string">'.'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>

<h3 id="d匹配任意的数字："><a href="#d匹配任意的数字：" class="headerlink" title="\d匹配任意的数字："></a>\d匹配任意的数字：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"123"</span></span><br><span class="line">ret = re.match(<span class="string">'\d'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="D匹配任意的非数字："><a href="#D匹配任意的非数字：" class="headerlink" title="\D匹配任意的非数字："></a>\D匹配任意的非数字：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"a"</span></span><br><span class="line">ret = re.match(<span class="string">'\D'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; a</span><br></pre></td></tr></table></figure>

<p>而如果text是等于一个数字，那么就匹配不成功了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"1"</span></span><br><span class="line">ret = re.match(<span class="string">'\D'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>

<h3 id="s匹配的是空白字符（包括：-n，-t，-r和空格）："><a href="#s匹配的是空白字符（包括：-n，-t，-r和空格）：" class="headerlink" title="\s匹配的是空白字符（包括：\n，\t，\r和空格）："></a>\s匹配的是空白字符（包括：\n，\t，\r和空格）：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"\t"</span></span><br><span class="line">ret = re.match(<span class="string">'\s'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; 空白</span><br></pre></td></tr></table></figure>

<h3 id="w匹配的是a-z和A-Z以及数字和下划线："><a href="#w匹配的是a-z和A-Z以及数字和下划线：" class="headerlink" title="\w匹配的是a-z和A-Z以及数字和下划线："></a>\w匹配的是<code>a-z</code>和<code>A-Z</code>以及数字和下划线：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"_"</span></span><br><span class="line">ret = re.match(<span class="string">'\w'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; _</span><br></pre></td></tr></table></figure>

<p>而如果要匹配一个其他的字符，那么就匹配不到。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"+"</span></span><br><span class="line">ret = re.match(<span class="string">'\w'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute</span><br></pre></td></tr></table></figure>

<h3 id="W匹配的是和-w相反的："><a href="#W匹配的是和-w相反的：" class="headerlink" title="\W匹配的是和\w相反的："></a>\W匹配的是和\w相反的：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"+"</span></span><br><span class="line">ret = re.match(<span class="string">'\W'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; +</span><br></pre></td></tr></table></figure>

<p>而如果你的text是一个下划线或者英文字符，那么就匹配不到了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"_"</span></span><br><span class="line">ret = re.match(<span class="string">'\W'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute</span><br></pre></td></tr></table></figure>

<h3 id="组合的方式，只要满足中括号中的某一项都算匹配成功："><a href="#组合的方式，只要满足中括号中的某一项都算匹配成功：" class="headerlink" title="[]组合的方式，只要满足中括号中的某一项都算匹配成功："></a>[]组合的方式，只要满足中括号中的某一项都算匹配成功：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"0731-88888888"</span></span><br><span class="line">ret = re.match(<span class="string">'[\d\-]+'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">0731</span><span class="number">-88888888</span></span><br></pre></td></tr></table></figure>

<p>之前讲到的几种匹配规则，其实可以使用中括号的形式来进行替代：</p>
<ul>
<li>\d：[0-9]</li>
<li>\D：<a href="#fn_0-9">0-9</a></li>
<li>\w：[0-9a-zA-Z_]</li>
<li>\W：[^0-9a-zA-Z_]</li>
</ul>
<h3 id="匹配多个字符："><a href="#匹配多个字符：" class="headerlink" title="匹配多个字符："></a>匹配多个字符：</h3><ol>
<li><p><code>*</code>：可以匹配0或者任意多个字符。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"0731"</span></span><br><span class="line">ret = re.match(<span class="string">'\d*'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">0731</span></span><br></pre></td></tr></table></figure>

<p>以上因为匹配的要求是<code>\d</code>，那么就要求是数字，后面跟了一个星号，就可以匹配到0731这四个字符。</p>
</li>
<li><p><code>+</code>：可以匹配1个或者多个字符。最少一个。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"abc"</span></span><br><span class="line">ret = re.match(<span class="string">'\w+'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; abc</span><br></pre></td></tr></table></figure>

<p>因为匹配的是<code>\w</code>，那么就要求是英文字符，后面跟了一个加号，意味着最少要有一个满足<code>\w</code>的字符才能够匹配到。如果text是一个空白字符或者是一个不满足\w的字符，那么就会报错。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">""</span></span><br><span class="line">ret = re.match(<span class="string">'\w+'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>?</code>：匹配的字符可以出现一次或者不出现（0或者1）。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"123"</span></span><br><span class="line">ret = re.match(<span class="string">'\d?'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>{m}</code>：匹配m个字符。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"123"</span></span><br><span class="line">ret = re.match(<span class="string">'\d&#123;2&#125;'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">12</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>{m,n}</code>：匹配m-n个字符。在这中间的字符都可以匹配到。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"123"</span></span><br><span class="line">ret = re.match(<span class="string">'\d&#123;1,2&#125;'</span>,text)</span><br><span class="line">prit(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">12</span></span><br></pre></td></tr></table></figure>

<p>如果text只有一个字符，那么也可以匹配出来。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"1"</span></span><br><span class="line">ret = re.match(<span class="string">'\d&#123;1,2&#125;'</span>,text)</span><br><span class="line">prit(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="小案例："><a href="#小案例：" class="headerlink" title="小案例："></a>小案例：</h3><ol>
<li><p>验证手机号码：手机号码的规则是以<code>1</code>开头，第二位可以是<code>34587</code>，后面那9位就可以随意了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"18570631587"</span></span><br><span class="line">ret = re.match(<span class="string">'1[34587]\d&#123;9&#125;'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">18570631587</span></span><br></pre></td></tr></table></figure>

<p>而如果是个不满足条件的手机号码。那么就匹配不到了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"1857063158"</span></span><br><span class="line">ret = re.match(<span class="string">'1[34587]\d&#123;9&#125;'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证邮箱：邮箱的规则是邮箱名称是用<code>数字、数字、下划线</code>组成的，然后是<code>@</code>符号，后面就是域名了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"hynever@163.com"</span></span><br><span class="line">ret = re.match(<span class="string">'\w+@\w+\.[a-zA-Z\.]+'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证URL：URL的规则是前面是<code>http</code>或者<code>https</code>或者是<code>ftp</code>然后再加上一个冒号，再加上一个斜杠，再后面就是可以出现任意非空白字符了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"http://www.baidu.com/"</span></span><br><span class="line">ret = re.match(<span class="string">'(http|https|ftp)://[^\s]+'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证身份证：身份证的规则是，总共有18位，前面17位都是数字，后面一位可以是数字，也可以是小写的x，也可以是大写的X。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"3113111890812323X"</span></span><br><span class="line">ret = re.match(<span class="string">'\d&#123;17&#125;[\dxX]'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="（脱字号）：表示以…开始："><a href="#（脱字号）：表示以…开始：" class="headerlink" title="^（脱字号）：表示以…开始："></a>^（脱字号）：表示以…开始：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"hello"</span></span><br><span class="line">ret = re.match(<span class="string">'^h'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<p>如果是在中括号中，那么代表的是取反操作.</p>
<h3 id="：表示以…结束："><a href="#：表示以…结束：" class="headerlink" title="$：表示以…结束："></a>$：表示以…结束：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 匹配163.com的邮箱</span></span><br><span class="line">text = <span class="string">"xxx@163.com"</span></span><br><span class="line">ret = re.search(<span class="string">'\w+@163\.com$'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; xxx@<span class="number">163.</span>com</span><br></pre></td></tr></table></figure>

<h3 id="：匹配多个表达式或者字符串："><a href="#：匹配多个表达式或者字符串：" class="headerlink" title="|：匹配多个表达式或者字符串："></a>|：匹配多个表达式或者字符串：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"hello|world"</span></span><br><span class="line">ret = re.search(<span class="string">'hello'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; hello</span><br></pre></td></tr></table></figure>

<h3 id="贪婪模式和非贪婪模式："><a href="#贪婪模式和非贪婪模式：" class="headerlink" title="贪婪模式和非贪婪模式："></a>贪婪模式和非贪婪模式：</h3><p>贪婪模式：正则表达式会匹配尽量多的字符。默认是贪婪模式。<br>非贪婪模式：正则表达式会尽量少的匹配字符。<br>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"0123456"</span></span><br><span class="line">ret = re.match(<span class="string">'\d+'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line"><span class="comment"># 因为默认采用贪婪模式，所以会输出0123456</span></span><br><span class="line">&gt;&gt; <span class="number">0123456</span></span><br></pre></td></tr></table></figure>

<p>可以改成非贪婪模式，那么就只会匹配到0。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"0123456"</span></span><br><span class="line">ret = re.match(<span class="string">'\d+?'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<h3 id="案例：匹配0-100之间的数字："><a href="#案例：匹配0-100之间的数字：" class="headerlink" title="案例：匹配0-100之间的数字："></a>案例：匹配<code>0-100</code>之间的数字：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'99'</span></span><br><span class="line">ret = re.match(<span class="string">'[1-9]?\d$|100$'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">99</span></span><br></pre></td></tr></table></figure>

<p>而如果<code>text=101</code>，那么就会抛出一个异常。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'101'</span></span><br><span class="line">ret = re.match(<span class="string">'[1-9]?\d$|100$'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>

<h3 id="转义字符和原生字符串："><a href="#转义字符和原生字符串：" class="headerlink" title="转义字符和原生字符串："></a>转义字符和原生字符串：</h3><p>在正则表达式中，有些字符是有特殊意义的字符。因此如果想要匹配这些字符，那么就必须使用反斜杠进行转义。比如<code>$</code>代表的是以…结尾，如果想要匹配<code>$</code>，那么就必须使用<code>\$</code>。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"apple price is \$99,orange paice is $88"</span></span><br><span class="line">ret = re.search(<span class="string">'\$(\d+)'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; $<span class="number">99</span></span><br></pre></td></tr></table></figure>

<p>原生字符串：<br>在正则表达式中，<code>\</code>是专门用来做转义的。在Python中<code>\</code>也是用来做转义的。因此如果想要在普通的字符串中匹配出<code>\</code>，那么要给出四个<code>\</code>。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"apple \c"</span></span><br><span class="line">ret = re.search(<span class="string">'\\\\c'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<p>因此要使用原生字符串就可以解决这个问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"apple \c"</span></span><br><span class="line">ret = re.search(<span class="string">r'\\c'</span>,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="re模块中常用函数："><a href="#re模块中常用函数：" class="headerlink" title="re模块中常用函数："></a>re模块中常用函数：</h2><h3 id="match："><a href="#match：" class="headerlink" title="match："></a>match：</h3><p>从开始的位置进行匹配。如果开始的位置没有匹配到。就直接失败了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'hello'</span></span><br><span class="line">ret = re.match(<span class="string">'h'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; h</span><br></pre></td></tr></table></figure>

<p>如果第一个字母不是<code>h</code>，那么就会失败。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'ahello'</span></span><br><span class="line">ret = re.match(<span class="string">'h'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; AttributeError: <span class="string">'NoneType'</span> object has no attribute <span class="string">'group'</span></span><br></pre></td></tr></table></figure>

<p>如果想要匹配换行的数据，那么就要传入一个<code>flag=re.DOTALL</code>，就可以匹配换行符了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"abc\nabc"</span></span><br><span class="line">ret = re.match(<span class="string">'abc.*abc'</span>,text,re.DOTALL)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<h3 id="search："><a href="#search：" class="headerlink" title="search："></a>search：</h3><p>在字符串中找满足条件的字符。如果找到，就返回。说白了，就是只会找到第一个满足条件的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'apple price $99 orange price $88'</span></span><br><span class="line">ret = re.search(<span class="string">'\d+'</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">&gt;&gt; <span class="number">99</span></span><br></pre></td></tr></table></figure>

<h3 id="分组："><a href="#分组：" class="headerlink" title="分组："></a>分组：</h3><p>在正则表达式中，可以对过滤到的字符串进行分组。分组使用圆括号的方式。</p>
<ol>
<li><code>group</code>：和<code>group(0)</code>是等价的，返回的是整个满足条件的字符串。</li>
<li><code>groups</code>：返回的是里面的子组。索引从1开始。</li>
<li><code>group(1)</code>：返回的是第一个子组，可以传入多个。<br>示例代码如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"apple price is $99,orange price is $10"</span></span><br><span class="line">ret = re.search(<span class="string">r".*(\$\d+).*(\$\d+)"</span>,text)</span><br><span class="line">print(ret.group())</span><br><span class="line">print(ret.group(<span class="number">0</span>))</span><br><span class="line">print(ret.group(<span class="number">1</span>))</span><br><span class="line">print(ret.group(<span class="number">2</span>))</span><br><span class="line">print(ret.groups())</span><br></pre></td></tr></table></figure>

<h3 id="findall："><a href="#findall：" class="headerlink" title="findall："></a>findall：</h3><p>找出所有满足条件的，返回的是一个列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'apple price $99 orange price $88'</span></span><br><span class="line">ret = re.findall(<span class="string">'\d+'</span>,text)</span><br><span class="line">print(ret)</span><br><span class="line">&gt;&gt; [<span class="string">'99'</span>, <span class="string">'88'</span>]</span><br></pre></td></tr></table></figure>

<h3 id="sub："><a href="#sub：" class="headerlink" title="sub："></a>sub：</h3><p>用来替换字符串。将匹配到的字符串替换为其他字符串。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">'apple price $99 orange price $88'</span></span><br><span class="line">ret = re.sub(<span class="string">'\d+'</span>,<span class="string">'0'</span>,text)</span><br><span class="line">print(ret)</span><br><span class="line">&gt;&gt; apple price $<span class="number">0</span> orange price $<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><code>sub</code>函数的案例，获取拉勾网中的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">html = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;基本要求：&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;1、精通HTML5、CSS3、 JavaScript等Web前端开发技术，对html5页面适配充分了解，熟悉不同浏览器间的差异，熟练写出兼容各种浏览器的代码；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;2、熟悉运用常见JS开发框架，如JQuery、vue、angular，能快速高效实现各种交互效果；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;3、熟悉编写能够自动适应HTML5界面，能让网页格式自动适应各款各大小的手机；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;4、利用HTML5相关技术开发移动平台、PC终端的前端页面，实现HTML5模板化；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;5、熟悉手机端和PC端web实现的差异，有移动平台web前端开发经验，了解移动互联网产品和行业，有在Android,iOS等平台下HTML5+CSS+JavaScript（或移动JS框架）开发经验者优先考虑；6、良好的沟通能力和团队协作精神，对移动互联网行业有浓厚兴趣，有较强的研究能力和学习能力；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;7、能够承担公司前端培训工作，对公司各业务线的前端（HTML5\CSS3）工作进行支撑和指导。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;&lt;br&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;岗位职责：&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;1、利用html5及相关技术开发移动平台、微信、APP等前端页面，各类交互的实现；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;2、持续的优化前端体验和页面响应速度，并保证兼容性和执行效率；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;3、根据产品需求，分析并给出最优的页面前端结构解决方案；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;4、协助后台及客户端开发人员完成功能开发和调试；&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;5、移动端主流浏览器的适配、移动端界面自适应研发。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">ret = re.sub(<span class="string">'&lt;/?[a-zA-Z0-9]+&gt;'</span>,<span class="string">""</span>,html)</span><br><span class="line">print(ret)</span><br></pre></td></tr></table></figure>

<h3 id="split："><a href="#split：" class="headerlink" title="split："></a>split：</h3><p>使用正则表达式来分割字符串。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"hello world ni hao"</span></span><br><span class="line">ret = re.split(<span class="string">'\W'</span>,text)</span><br><span class="line">print(ret)</span><br><span class="line">&gt;&gt; [<span class="string">"hello"</span>,<span class="string">"world"</span>,<span class="string">"ni"</span>,<span class="string">"hao"</span>]</span><br></pre></td></tr></table></figure>

<h3 id="compile："><a href="#compile：" class="headerlink" title="compile："></a>compile：</h3><p>对于一些经常要用到的正则表达式，可以使用<code>compile</code>进行编译，后期再使用的时候可以直接拿过来用，执行效率会更快。而且<code>compile</code>还可以指定<code>flag=re.VERBOSE</code>，在写正则表达式的时候可以做好注释。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"the number is 20.50"</span></span><br><span class="line">r = re.compile(<span class="string">r"""</span></span><br><span class="line"><span class="string">                \d+ # 小数点前面的数字</span></span><br><span class="line"><span class="string">                \.? # 小数点</span></span><br><span class="line"><span class="string">                \d* # 小数点后面的数字</span></span><br><span class="line"><span class="string">                """</span>,re.VERBOSE)</span><br><span class="line">ret = re.search(r,text)</span><br><span class="line">print(ret.group())</span><br></pre></td></tr></table></figure>

<h1 id="json文件处理："><a href="#json文件处理：" class="headerlink" title="json文件处理："></a>json文件处理：</h1><h2 id="什么是json："><a href="#什么是json：" class="headerlink" title="什么是json："></a>什么是json：</h2><p>JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式。它基于 ECMAScript (w3c制定的js规范)的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。更多解释请见：<a href="https://baike.baidu.com/item/JSON/2462549?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/JSON/2462549?fr=aladdin</a></p>
<h2 id="JSON支持数据格式："><a href="#JSON支持数据格式：" class="headerlink" title="JSON支持数据格式："></a>JSON支持数据格式：</h2><ol>
<li>对象（字典）。使用花括号。</li>
<li>数组（列表）。使用方括号。</li>
<li>整形、浮点型、布尔类型还有null类型。</li>
<li>字符串类型（字符串必须要用双引号，不能用单引号）。</li>
</ol>
<p>多个数据之间使用逗号分开。<br><strong>注意：json本质上就是一个字符串。</strong></p>
<h2 id="字典和列表转JSON："><a href="#字典和列表转JSON：" class="headerlink" title="字典和列表转JSON："></a>字典和列表转JSON：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">books = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'title'</span>: <span class="string">'钢铁是怎样练成的'</span>,</span><br><span class="line">        <span class="string">'price'</span>: <span class="number">9.8</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'title'</span>: <span class="string">'红楼梦'</span>,</span><br><span class="line">        <span class="string">'price'</span>: <span class="number">9.9</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">json_str = json.dumps(books,ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">print(json_str)</span><br></pre></td></tr></table></figure>

<p>因为<code>json</code>在<code>dump</code>的时候，只能存放<code>ascii</code>的字符，因此会将中文进行转义，这时候我们可以使用<code>ensure_ascii=False</code>关闭这个特性。<br>在<code>Python</code>中。只有基本数据类型才能转换成<code>JSON</code>格式的字符串。也即：<code>int</code>、<code>float</code>、<code>str</code>、<code>list</code>、<code>dict</code>、<code>tuple</code>。</p>
<h3 id="将json数据直接dump到文件中："><a href="#将json数据直接dump到文件中：" class="headerlink" title="将json数据直接dump到文件中："></a>将json数据直接<code>dump</code>到文件中：</h3><p><code>json</code>模块中除了<code>dumps</code>函数，还有一个<code>dump</code>函数，这个函数可以传入一个文件指针，直接将字符串<code>dump</code>到文件中。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">books = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'title'</span>: <span class="string">'钢铁是怎样练成的'</span>,</span><br><span class="line">        <span class="string">'price'</span>: <span class="number">9.8</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'title'</span>: <span class="string">'红楼梦'</span>,</span><br><span class="line">        <span class="string">'price'</span>: <span class="number">9.9</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'a.json'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(books,fp)</span><br></pre></td></tr></table></figure>

<h2 id="将一个json字符串load成Python对象："><a href="#将一个json字符串load成Python对象：" class="headerlink" title="将一个json字符串load成Python对象："></a>将一个json字符串load成Python对象：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">json_str = <span class="string">'[&#123;"title": "钢铁是怎样练成的", "price": 9.8&#125;, &#123;"title": "红楼梦", "price": 9.9&#125;]'</span></span><br><span class="line">books = json.loads(json_str,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">print(type(books))</span><br><span class="line">print(books)</span><br></pre></td></tr></table></figure>

<h3 id="直接从文件中读取json："><a href="#直接从文件中读取json：" class="headerlink" title="直接从文件中读取json："></a>直接从文件中读取json：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'a.json'</span>,<span class="string">'r'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json_str = json.load(fp)</span><br><span class="line">    print(json_str)</span><br></pre></td></tr></table></figure>

<h1 id="csv文件处理"><a href="#csv文件处理" class="headerlink" title="csv文件处理"></a>csv文件处理</h1><h2 id="读取csv文件："><a href="#读取csv文件：" class="headerlink" title="读取csv文件："></a>读取csv文件：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'stock.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    reader = csv.reader(fp)</span><br><span class="line">    titles = next(reader)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> reader:</span><br><span class="line">        print(x)</span><br></pre></td></tr></table></figure>

<p>这样操作，以后获取数据的时候，就要通过下表来获取数据。如果想要在获取数据的时候通过标题来获取。那么可以使用<code>DictReader</code>。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'stock.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    reader = csv.DictReader(fp)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> reader:</span><br><span class="line">        print(x[<span class="string">'turnoverVol'</span>])</span><br></pre></td></tr></table></figure>

<h2 id="写入数据到csv文件："><a href="#写入数据到csv文件：" class="headerlink" title="写入数据到csv文件："></a>写入数据到csv文件：</h2><p>写入数据到csv文件，需要创建一个<code>writer</code>对象，主要用到两个方法。一个是<code>writerow</code>，这个是写入一行。一个是<code>writerows</code>，这个是写入多行。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">headers = [<span class="string">'name'</span>,<span class="string">'age'</span>,<span class="string">'classroom'</span>]</span><br><span class="line">values = [</span><br><span class="line">    (<span class="string">'zhiliao'</span>,<span class="number">18</span>,<span class="string">'111'</span>),</span><br><span class="line">    (<span class="string">'wena'</span>,<span class="number">20</span>,<span class="string">'222'</span>),</span><br><span class="line">    (<span class="string">'bbc'</span>,<span class="number">21</span>,<span class="string">'111'</span>)</span><br><span class="line">]</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test.csv'</span>,<span class="string">'w'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    writer = csv.writer(fp)</span><br><span class="line">    writer.writerow(headers)</span><br><span class="line">    writer.writerows(values)</span><br></pre></td></tr></table></figure>

<p>也可以使用字典的方式把数据写入进去。这时候就需要使用<code>DictWriter</code>了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line">headers = [<span class="string">'name'</span>,<span class="string">'age'</span>,<span class="string">'classroom'</span>]</span><br><span class="line">values = [</span><br><span class="line">    &#123;<span class="string">"name"</span>:<span class="string">'wenn'</span>,<span class="string">"age"</span>:<span class="number">20</span>,<span class="string">"classroom"</span>:<span class="string">'222'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">"name"</span>:<span class="string">'abc'</span>,<span class="string">"age"</span>:<span class="number">30</span>,<span class="string">"classroom"</span>:<span class="string">'333'</span>&#125;</span><br><span class="line">]</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test.csv'</span>,<span class="string">'w'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    writer = csv.DictWriter(fp,headers)</span><br><span class="line">    writer = csv.writeheader()</span><br><span class="line">    writer.writerow(&#123;<span class="string">'name'</span>:<span class="string">'zhiliao'</span>,<span class="string">"age"</span>:<span class="number">18</span>,<span class="string">"classroom"</span>:<span class="string">'111'</span>&#125;)</span><br><span class="line">    writer.writerows(values)</span><br></pre></td></tr></table></figure>

<p>对于csv文件的操作python提供了<strong>pandas库</strong>，以更灵活的方式来操作二维表。</p>
<h1 id="MySQL数据库操作"><a href="#MySQL数据库操作" class="headerlink" title="MySQL数据库操作"></a>MySQL数据库操作</h1><h2 id="安装mysql："><a href="#安装mysql：" class="headerlink" title="安装mysql："></a>安装mysql：</h2><ol>
<li>在官网：<a href="https://dev.mysql.com/downloads/windows/installer/5.7.html" target="_blank" rel="noopener">https://dev.mysql.com/downloads/windows/installer/5.7.html</a></li>
<li>如果提示没有<code>.NET Framework</code>框架。那么就在提示框中找到下载链接，下载一个就可以了。</li>
<li>如果提示没有<code>Microsoft Virtual C++ x64(x86)</code>，那么百度或者谷歌这个软件安装即可。</li>
<li>如果没有找到。那么私聊我。</li>
</ol>
<h2 id="navicat："><a href="#navicat：" class="headerlink" title="navicat："></a>navicat：</h2><p>navicat是一个操作mysql数据库非常方便的软件。使用他操作数据库，就跟使用excel操作数据是一样的。</p>
<h2 id="安装驱动程序："><a href="#安装驱动程序：" class="headerlink" title="安装驱动程序："></a>安装驱动程序：</h2><p>Python要想操作MySQL。必须要有一个中间件，或者叫做驱动程序。驱动程序有很多。比如有<code>mysqldb</code>、<code>mysqlclient</code>、<code>pymysql</code>等。在这里，我们选择用<code>pymysql</code>。安装方式也是非常简单，通过命令<code>pip install pymysql</code>即可安装。</p>
<h2 id="数据库连接："><a href="#数据库连接：" class="headerlink" title="数据库连接："></a>数据库连接：</h2><p>数据库连接之前。首先先确认以下工作完成，这里我们以一个<code>pymysql_test</code>数据库.以下将介绍连接<code>mysql</code>的示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line">db = pymysql.connect(</span><br><span class="line">    host=<span class="string">"127.0.0.1"</span>,</span><br><span class="line">    user=<span class="string">'root'</span>,</span><br><span class="line">    password=<span class="string">'root'</span>,</span><br><span class="line">    database=<span class="string">'pymysql_test'</span>,</span><br><span class="line">    port=<span class="number">3306</span></span><br><span class="line">)</span><br><span class="line">cursor = db.cursor()</span><br><span class="line">cursor.execute(<span class="string">"select 1"</span>)</span><br><span class="line">data = cursor.fetchone()</span><br><span class="line">print(data)</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<h2 id="插入数据："><a href="#插入数据：" class="headerlink" title="插入数据："></a>插入数据：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line">db = pymysql.connect(</span><br><span class="line">    host=<span class="string">"127.0.0.1"</span>,</span><br><span class="line">    user=<span class="string">'root'</span>,</span><br><span class="line">    password=<span class="string">'root'</span>,</span><br><span class="line">    database=<span class="string">'pymysql_test'</span>,</span><br><span class="line">    port=<span class="number">3306</span></span><br><span class="line">)</span><br><span class="line">cursor = db.cursor()</span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">insert into user(</span></span><br><span class="line"><span class="string">    id,username,gender,age,password</span></span><br><span class="line"><span class="string">  ) </span></span><br><span class="line"><span class="string">  values(null,'abc',1,18,'111111');</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">db.commit()</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<p>如果在数据还不能保证的情况下，可以使用以下方式来插入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">insert into user(</span></span><br><span class="line"><span class="string">    id,username,gender,age,password</span></span><br><span class="line"><span class="string">  ) </span></span><br><span class="line"><span class="string">  values(null,%s,%s,%s,%s);</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql,(<span class="string">'spider'</span>,<span class="number">1</span>,<span class="number">20</span>,<span class="string">'222222'</span>))</span><br></pre></td></tr></table></figure>

<h2 id="查找数据："><a href="#查找数据：" class="headerlink" title="查找数据："></a>查找数据：</h2><p>使用<code>pymysql</code>查询数据。可以使用<code>fetch*</code>方法。</p>
<ol>
<li><code>fetchone()</code>：这个方法每次之获取一条数据。</li>
<li><code>fetchall()</code>：这个方法接收全部的返回结果。</li>
<li><code>fetchmany(size)</code>：可以获取指定条数的数据。<br>示例代码如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">select * from user</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    result = cursor.fetchone()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(result)</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<p>或者是直接使用<code>fetchall</code>，一次性可以把所有满足条件的数据都取出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">select * from user</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">results = cursor.fetchall()</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    print(result)</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<p>或者是使用<code>fetchmany</code>，指定获取多少条数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">select * from user</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">results = cursor.fetchmany(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    print(result)</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<h2 id="删除数据："><a href="#删除数据：" class="headerlink" title="删除数据："></a>删除数据：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">delete from user where id=1</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">db.commit()</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>

<h2 id="更新数据："><a href="#更新数据：" class="headerlink" title="更新数据："></a>更新数据：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">conn = pymysql.connect(host=<span class="string">'localhost'</span>,user=<span class="string">'root'</span>,password=<span class="string">'root'</span>,database=<span class="string">'pymysql_demo'</span>,port=<span class="number">3306</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line"></span><br><span class="line">sql = <span class="string">"""</span></span><br><span class="line"><span class="string">update user set username='aaa' where id=1</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line">conn.commit()</span><br><span class="line"></span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure>

<h1 id="多线程爬虫"><a href="#多线程爬虫" class="headerlink" title="多线程爬虫"></a>多线程爬虫</h1><p>有些时候，比如下载图片，因为下载图片是一个耗时的操作。如果采用之前那种同步的方式下载。那效率肯会特别慢。这时候我们就可以考虑使用多线程的方式来下载图片。</p>
<h2 id="多线程介绍："><a href="#多线程介绍：" class="headerlink" title="多线程介绍："></a>多线程介绍：</h2><p>多线程是为了同步完成多项任务，通过提高资源使用效率来提高系统的效率。线程是在同一时间需要完成多项任务的时候实现的。<br>最简单的比喻多线程就像火车的每一节车厢，而进程则是火车。车厢离开火车是无法跑动的，同理火车也可以有多节车厢。多线程的出现就是为了提高效率。同时它的出现也带来了一些问题。更多介绍请参考：<a href="https://baike.baidu.com/item/多线程/1190404?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/多线程/1190404?fr=aladdin</a></p>
<h2 id="threading模块介绍："><a href="#threading模块介绍：" class="headerlink" title="threading模块介绍："></a>threading模块介绍：</h2><p><code>threading</code>模块是<code>python</code>中专门提供用来做多线程编程的模块。<code>threading</code>模块中最常用的类是<code>Thread</code>。以下看一个简单的多线程程序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">coding</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        print(<span class="string">'%s正在写代码'</span> % x)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawing</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        print(<span class="string">'%s正在画图'</span> % x)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_thread</span><span class="params">()</span>:</span></span><br><span class="line">    coding()</span><br><span class="line">    drawing()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_thread</span><span class="params">()</span>:</span></span><br><span class="line">    t1 = threading.Thread(target=coding)</span><br><span class="line">    t2 = threading.Thread(target=drawing)</span><br><span class="line"></span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    multi_thread()</span><br></pre></td></tr></table></figure>

<h3 id="查看线程数："><a href="#查看线程数：" class="headerlink" title="查看线程数："></a>查看线程数：</h3><p>使用<code>threading.enumerate()</code>函数便可以看到当前线程的数量。</p>
<h3 id="查看当前线程的名字："><a href="#查看当前线程的名字：" class="headerlink" title="查看当前线程的名字："></a>查看当前线程的名字：</h3><p>使用<code>threading.current_thread()</code>可以看到当前线程的信息。</p>
<h3 id="继承自threading-Thread类："><a href="#继承自threading-Thread类：" class="headerlink" title="继承自threading.Thread类："></a>继承自<code>threading.Thread</code>类：</h3><p>为了让线程代码更好的封装。可以使用<code>threading</code>模块下的<code>Thread</code>类，继承自这个类，然后实现<code>run</code>方法，线程就会自动运行<code>run</code>方法中的代码。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CodingThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            print(<span class="string">'%s正在写代码'</span> % threading.current_thread())</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DrawingThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            print(<span class="string">'%s正在画图'</span> % threading.current_thread())</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_thread</span><span class="params">()</span>:</span></span><br><span class="line">    t1 = CodingThread()</span><br><span class="line">    t2 = DrawingThread()</span><br><span class="line"></span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    multi_thread()</span><br></pre></td></tr></table></figure>

<h3 id="多线程共享全局变量的问题："><a href="#多线程共享全局变量的问题：" class="headerlink" title="多线程共享全局变量的问题："></a>多线程共享全局变量的问题：</h3><p>多线程都是在同一个进程中运行的。因此在进程中的全局变量所有线程都是可共享的。这就造成了一个问题，因为线程执行的顺序是无序的。有可能会造成数据错误。比如以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">tickets = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ticket</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> tickets</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">        tickets += <span class="number">1</span></span><br><span class="line">    print(<span class="string">'tickets:%d'</span>%tickets)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        t = threading.Thread(target=get_ticket)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>以上结果正常来讲应该是6，但是因为多线程运行的不确定性。因此最后的结果可能是随机的。</p>
<h3 id="锁机制："><a href="#锁机制：" class="headerlink" title="锁机制："></a>锁机制：</h3><p>为了解决以上使用共享全局变量的问题。<code>threading</code>提供了一个<code>Lock</code>类，这个类可以在某个线程访问某个变量的时候加锁，其他线程此时就不能进来，直到当前线程处理完后，把锁释放了，其他线程才能进来处理。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">VALUE = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">gLock = threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_value</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> VALUE</span><br><span class="line">    gLock.acquire()</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">        VALUE += <span class="number">1</span></span><br><span class="line">    gLock.release()</span><br><span class="line">    print(<span class="string">'value：%d'</span>%VALUE)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        t = threading.Thread(target=add_value)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="Lock版本生产者和消费者模式："><a href="#Lock版本生产者和消费者模式：" class="headerlink" title="Lock版本生产者和消费者模式："></a>Lock版本生产者和消费者模式：</h2><p>生产者和消费者模式是多线程开发中经常见到的一种模式。生产者的线程专门用来生产一些数据，然后存放到一个中间的变量中。消费者再从这个中间的变量中取出数据进行消费。但是因为要使用中间变量，中间变量经常是一些全局变量，因此需要使用锁来保证数据完整性。以下是使用<code>threading.Lock</code>锁实现的“生产者与消费者模式”的一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">gMoney = <span class="number">1000</span></span><br><span class="line">gLock = threading.Lock()</span><br><span class="line"><span class="comment"># 记录生产者生产的次数，达到10次就不再生产</span></span><br><span class="line">gTimes = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> gMoney</span><br><span class="line">        <span class="keyword">global</span> gLock</span><br><span class="line">        <span class="keyword">global</span> gTimes</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            money = random.randint(<span class="number">100</span>, <span class="number">1000</span>)</span><br><span class="line">            gLock.acquire()</span><br><span class="line">            <span class="comment"># 如果已经达到10次了，就不再生产了</span></span><br><span class="line">            <span class="keyword">if</span> gTimes &gt;= <span class="number">10</span>:</span><br><span class="line">                gLock.release()</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            gMoney += money</span><br><span class="line">            print(<span class="string">'%s当前存入%s元钱，剩余%s元钱'</span> % (threading.current_thread(), money, gMoney))</span><br><span class="line">            gTimes += <span class="number">1</span></span><br><span class="line">            time.sleep(<span class="number">0.5</span>)</span><br><span class="line">            gLock.release()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> gMoney</span><br><span class="line">        <span class="keyword">global</span> gLock</span><br><span class="line">        <span class="keyword">global</span> gTimes</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            money = random.randint(<span class="number">100</span>, <span class="number">500</span>)</span><br><span class="line">            gLock.acquire()</span><br><span class="line">            <span class="keyword">if</span> gMoney &gt; money:</span><br><span class="line">                gMoney -= money</span><br><span class="line">                print(<span class="string">'%s当前取出%s元钱，剩余%s元钱'</span> % (threading.current_thread(), money, gMoney))</span><br><span class="line">                time.sleep(<span class="number">0.5</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果钱不够了，有可能是已经超过了次数，这时候就判断一下</span></span><br><span class="line">                <span class="keyword">if</span> gTimes &gt;= <span class="number">10</span>:</span><br><span class="line">                    gLock.release()</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                print(<span class="string">"%s当前想取%s元钱，剩余%s元钱，不足！"</span> % (threading.current_thread(),money,gMoney))</span><br><span class="line">            gLock.release()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        Consumer(name=<span class="string">'消费者线程%d'</span>%x).start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        Producer(name=<span class="string">'生产者线程%d'</span>%x).start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="Condition版的生产者与消费者模式："><a href="#Condition版的生产者与消费者模式：" class="headerlink" title="Condition版的生产者与消费者模式："></a>Condition版的生产者与消费者模式：</h2><p><code>Lock</code>版本的生产者与消费者模式可以正常的运行。但是存在一个不足，在消费者中，总是通过<code>while True</code>死循环并且上锁的方式去判断钱够不够。上锁是一个很耗费CPU资源的行为。因此这种方式不是最好的。还有一种更好的方式便是使用<code>threading.Condition</code>来实现。<code>threading.Condition</code>可以在没有数据的时候处于阻塞等待状态。一旦有合适的数据了，还可以使用<code>notify</code>相关的函数来通知其他处于等待状态的线程。这样就可以不用做一些无用的上锁和解锁的操作。可以提高程序的性能。首先对<code>threading.Condition</code>相关的函数做个介绍，<code>threading.Condition</code>类似<code>threading.Lock</code>，可以在修改全局数据的时候进行上锁，也可以在修改完毕后进行解锁。以下将一些常用的函数做个简单的介绍：</p>
<ol>
<li><code>acquire</code>：上锁。</li>
<li><code>release</code>：解锁。</li>
<li><code>wait</code>：将当前线程处于等待状态，并且会释放锁。可以被其他线程使用<code>notify</code>和<code>notify_all</code>函数唤醒。被唤醒后会继续等待上锁，上锁后继续执行下面的代码。</li>
<li><code>notify</code>：通知某个正在等待的线程，默认是第1个等待的线程。</li>
<li><code>notify_all</code>：通知所有正在等待的线程。<code>notify</code>和<code>notify_all</code>不会释放锁。并且需要在<code>release</code>之前调用。</li>
</ol>
<p><code>Condition</code>版的生产者与消费者模式代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">gMoney = <span class="number">1000</span></span><br><span class="line">gCondition = threading.Condition()</span><br><span class="line">gTimes = <span class="number">0</span></span><br><span class="line">gTotalTimes = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> gMoney</span><br><span class="line">        <span class="keyword">global</span> gCondition</span><br><span class="line">        <span class="keyword">global</span> gTimes</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            money = random.randint(<span class="number">100</span>, <span class="number">1000</span>)</span><br><span class="line">            gCondition.acquire()</span><br><span class="line">            <span class="keyword">if</span> gTimes &gt;= gTotalTimes:</span><br><span class="line">                gCondition.release()</span><br><span class="line">                print(<span class="string">'当前生产者总共生产了%s次'</span>%gTimes)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            gMoney += money</span><br><span class="line">            print(<span class="string">'%s当前存入%s元钱，剩余%s元钱'</span> % (threading.current_thread(), money, gMoney))</span><br><span class="line">            gTimes += <span class="number">1</span></span><br><span class="line">            time.sleep(<span class="number">0.5</span>)</span><br><span class="line">            gCondition.notify_all()</span><br><span class="line">            gCondition.release()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">global</span> gMoney</span><br><span class="line">        <span class="keyword">global</span> gCondition</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            money = random.randint(<span class="number">100</span>, <span class="number">500</span>)</span><br><span class="line">            gCondition.acquire()</span><br><span class="line">            <span class="comment"># 这里要给个while循环判断，因为等轮到这个线程的时候</span></span><br><span class="line">            <span class="comment"># 条件有可能又不满足了</span></span><br><span class="line">            <span class="keyword">while</span> gMoney &lt; money:</span><br><span class="line">                <span class="keyword">if</span> gTimes &gt;= gTotalTimes:</span><br><span class="line">                    gCondition.release()</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                print(<span class="string">'%s准备取%s元钱，剩余%s元钱，不足！'</span>%(threading.current_thread(),money,gMoney))</span><br><span class="line">                gCondition.wait()</span><br><span class="line">            gMoney -= money</span><br><span class="line">            print(<span class="string">'%s当前取出%s元钱，剩余%s元钱'</span> % (threading.current_thread(), money, gMoney))</span><br><span class="line">            time.sleep(<span class="number">0.5</span>)</span><br><span class="line">            gCondition.release()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        Consumer(name=<span class="string">'消费者线程%d'</span>%x).start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        Producer(name=<span class="string">'生产者线程%d'</span>%x).start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="Queue线程安全队列："><a href="#Queue线程安全队列：" class="headerlink" title="Queue线程安全队列："></a>Queue线程安全队列：</h2><p>在线程中，访问一些全局变量，加锁是一个经常的过程。如果你是想把一些数据存储到某个队列中，那么Python内置了一个线程安全的模块叫做<code>queue</code>模块。Python中的queue模块中提供了同步的、线程安全的队列类，包括FIFO（先进先出）队列Queue，LIFO（后入先出）队列LifoQueue。这些队列都实现了锁原语（可以理解为原子操作，即要么不做，要么都做完），能够在多线程中直接使用。可以使用队列来实现线程间的同步。相关的函数如下：</p>
<ol>
<li>初始化Queue(maxsize)：创建一个先进先出的队列。</li>
<li>qsize()：返回队列的大小。</li>
<li>empty()：判断队列是否为空。</li>
<li>full()：判断队列是否满了。</li>
<li>get()：从队列中取最后一个数据。</li>
<li>put()：将一个数据放到队列中。</li>
</ol>
<h2 id="使用生产者与消费者模式多线程下载表情包："><a href="#使用生产者与消费者模式多线程下载表情包：" class="headerlink" title="使用生产者与消费者模式多线程下载表情包："></a>使用生产者与消费者模式多线程下载表情包：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,page_queue,img_queue,*args,**kwargs)</span>:</span></span><br><span class="line">        super(Producer, self).__init__(*args,**kwargs)</span><br><span class="line">        self.page_queue = page_queue</span><br><span class="line">        self.img_queue = img_queue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.page_queue.empty():</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            url = self.page_queue.get()</span><br><span class="line">            self.parse_page(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        text = response.text</span><br><span class="line">        html = etree.HTML(text)</span><br><span class="line">        imgs = html.xpath(<span class="string">"//div[@class='page-content text-center']//a//img"</span>)</span><br><span class="line">        <span class="keyword">for</span> img <span class="keyword">in</span> imgs:</span><br><span class="line">            <span class="keyword">if</span> img.get(<span class="string">'class'</span>) == <span class="string">'gif'</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            img_url = img.xpath(<span class="string">".//@data-original"</span>)[<span class="number">0</span>]</span><br><span class="line">            suffix = os.path.splitext(img_url)[<span class="number">1</span>]</span><br><span class="line">            alt = img.xpath(<span class="string">".//@alt"</span>)[<span class="number">0</span>]</span><br><span class="line">            alt = re.sub(<span class="string">r'[，。？?,/\\·]'</span>,<span class="string">''</span>,alt)</span><br><span class="line">            img_name = alt + suffix</span><br><span class="line">            self.img_queue.put((img_url,img_name))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,page_queue,img_queue,*args,**kwargs)</span>:</span></span><br><span class="line">        super(Consumer, self).__init__(*args,**kwargs)</span><br><span class="line">        self.page_queue = page_queue</span><br><span class="line">        self.img_queue = img_queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.img_queue.empty():</span><br><span class="line">                <span class="keyword">if</span> self.page_queue.empty():</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">            img = self.img_queue.get(block=<span class="literal">True</span>)</span><br><span class="line">            url,filename = img</span><br><span class="line">            request.urlretrieve(url,<span class="string">'images/'</span>+filename)</span><br><span class="line">            print(filename+<span class="string">'  下载完成！'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    page_queue = Queue(<span class="number">100</span>)</span><br><span class="line">    img_queue = Queue(<span class="number">500</span>)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</span><br><span class="line">        url = <span class="string">"http://www.doutula.com/photo/list/?page=%d"</span> % x</span><br><span class="line">        page_queue.put(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = Producer(page_queue,img_queue)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = Consumer(page_queue,img_queue)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="GIL全局解释器锁："><a href="#GIL全局解释器锁：" class="headerlink" title="GIL全局解释器锁："></a>GIL全局解释器锁：</h2><p>Python自带的解释器是<code>CPython</code>。<code>CPython</code>解释器的多线程实际上是一个假的多线程（在多核CPU中，只能利用一核，不能利用多核）。同一时刻只有一个线程在执行，为了保证同一时刻只有一个线程在执行，在<code>CPython</code>解释器中有一个东西叫做<code>GIL（Global Intepreter Lock）</code>，叫做全局解释器锁。这个解释器锁是有必要的。因为<code>CPython</code>解释器的内存管理不是线程安全的。当然除了<code>CPython</code>解释器，还有其他的解释器，有些解释器是没有<code>GIL</code>锁的，见下面：</p>
<ol>
<li><code>Jython</code>：用Java实现的Python解释器。不存在GIL锁。更多详情请见：<a href="https://zh.wikipedia.org/wiki/Jython" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Jython</a></li>
<li><code>IronPython</code>：用<code>.net</code>实现的Python解释器。不存在GIL锁。更多详情请见：<a href="https://zh.wikipedia.org/wiki/IronPython" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/IronPython</a></li>
<li><code>PyPy</code>：用<code>Python</code>实现的Python解释器。存在GIL锁。更多详情请见：<a href="https://zh.wikipedia.org/wiki/PyPy" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/PyPy</a><br>GIL虽然是一个假的多线程。但是在处理一些IO操作（比如文件读写和网络请求）还是可以在很大程度上提高效率的。在IO操作上建议使用多线程提高效率。在一些CPU计算操作上不建议使用多线程，而建议使用多进程。</li>
</ol>
<h2 id="多线程下载百思不得姐段子作业："><a href="#多线程下载百思不得姐段子作业：" class="headerlink" title="多线程下载百思不得姐段子作业："></a>多线程下载百思不得姐段子作业：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BSSpider</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,page_queue,joke_queue,*args,**kwargs)</span>:</span></span><br><span class="line">        super(BSSpider, self).__init__(*args,**kwargs)</span><br><span class="line">        self.base_domain = <span class="string">'http://www.budejie.com'</span></span><br><span class="line">        self.page_queue = page_queue</span><br><span class="line">        self.joke_queue = joke_queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> self.page_queue.empty():</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            url = self.page_queue.get()</span><br><span class="line">            response = requests.get(url, headers=self.headers)</span><br><span class="line">            text = response.text</span><br><span class="line">            html = etree.HTML(text)</span><br><span class="line">            descs = html.xpath(<span class="string">"//div[@class='j-r-list-c-desc']"</span>)</span><br><span class="line">            <span class="keyword">for</span> desc <span class="keyword">in</span> descs:</span><br><span class="line">                jokes = desc.xpath(<span class="string">".//text()"</span>)</span><br><span class="line">                joke = <span class="string">"\n"</span>.join(jokes).strip()</span><br><span class="line">                link = self.base_domain+desc.xpath(<span class="string">".//a/@href"</span>)[<span class="number">0</span>]</span><br><span class="line">                self.joke_queue.put((joke,link))</span><br><span class="line">            print(<span class="string">'='</span>*<span class="number">30</span>+<span class="string">"第%s页下载完成！"</span>%url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]+<span class="string">"="</span>*<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BSWriter</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, joke_queue, writer,gLock, *args, **kwargs)</span>:</span></span><br><span class="line">        super(BSWriter, self).__init__(*args, **kwargs)</span><br><span class="line">        self.joke_queue = joke_queue</span><br><span class="line">        self.writer = writer</span><br><span class="line">        self.lock = gLock</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                joke_info = self.joke_queue.get(timeout=<span class="number">40</span>)</span><br><span class="line">                joke,link = joke_info</span><br><span class="line">                self.lock.acquire()</span><br><span class="line">                self.writer.writerow((joke,link))</span><br><span class="line">                self.lock.release()</span><br><span class="line">                print(<span class="string">'保存一条'</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    page_queue = Queue(<span class="number">10</span>)</span><br><span class="line">    joke_queue = Queue(<span class="number">500</span>)</span><br><span class="line">    gLock = threading.Lock()</span><br><span class="line">    fp = open(<span class="string">'bsbdj.csv'</span>, <span class="string">'a'</span>,newline=<span class="string">''</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    writer = csv.writer(fp)</span><br><span class="line">    writer.writerow((<span class="string">'content'</span>, <span class="string">'link'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">        url = <span class="string">'http://www.budejie.com/text/%d'</span> % x</span><br><span class="line">        page_queue.put(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = BSSpider(page_queue,joke_queue)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        t = BSWriter(joke_queue,writer,gLock)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h1 id="动态网页数据抓取"><a href="#动态网页数据抓取" class="headerlink" title="动态网页数据抓取"></a>动态网页数据抓取</h1><h2 id="什么是AJAX："><a href="#什么是AJAX：" class="headerlink" title="什么是AJAX："></a>什么是AJAX：</h2><p>AJAX（Asynchronouse JavaScript And XML）异步JavaScript和XML。过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用Ajax）如果需要更新内容，必须重载整个网页页面。因为传统的在传输数据格式方面，使用的是<code>XML</code>语法。因此叫做<code>AJAX</code>，其实现在数据交互基本上都是使用<code>JSON</code>。使用AJAX加载的数据，即使使用了JS，将数据渲染到了浏览器中，在<code>右键-&gt;查看网页源代码</code>还是不能看到通过ajax加载的数据，只能看到使用这个url加载的html代码。</p>
<h2 id="获取ajax数据的方式："><a href="#获取ajax数据的方式：" class="headerlink" title="获取ajax数据的方式："></a>获取ajax数据的方式：</h2><ol>
<li>直接分析ajax调用的接口。然后通过代码请求这个接口。</li>
<li>使用Selenium+chromedriver模拟浏览器行为获取数据。</li>
</ol>
<table>
<thead>
<tr>
<th>方式</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>分析接口</td>
<td>直接可以请求到数据。不需要做一些解析工作。代码量少，性能高。</td>
<td>分析接口比较复杂，特别是一些通过js混淆的接口，要有一定的js功底。容易被发现是爬虫。</td>
</tr>
<tr>
<td>selenium</td>
<td>直接模拟浏览器的行为。浏览器能请求到的，使用selenium也能请求到。爬虫更稳定。</td>
<td>代码量多。性能低。</td>
</tr>
</tbody></table>
<h2 id="Selenium-chromedriver获取动态数据："><a href="#Selenium-chromedriver获取动态数据：" class="headerlink" title="Selenium+chromedriver获取动态数据："></a>Selenium+chromedriver获取动态数据：</h2><p><code>Selenium</code>相当于是一个机器人。可以模拟人类在浏览器上的一些行为，自动处理浏览器上的一些行为，比如点击，填充数据，删除cookie等。<code>chromedriver</code>是一个驱动<code>Chrome</code>浏览器的驱动程序，使用他才可以驱动浏览器。当然针对不同的浏览器有不同的driver。以下列出了不同浏览器及其对应的driver：</p>
<ol>
<li>Chrome：<a href="https://sites.google.com/a/chromium.org/chromedriver/downloads" target="_blank" rel="noopener">https://sites.google.com/a/chromium.org/chromedriver/downloads</a></li>
<li>Firefox：<a href="https://github.com/mozilla/geckodriver/releases">https://github.com/mozilla/geckodriver/releases</a></li>
<li>Edge：<a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/" target="_blank" rel="noopener">https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/</a></li>
<li>Safari：<a href="https://webkit.org/blog/6900/webdriver-support-in-safari-10/" target="_blank" rel="noopener">https://webkit.org/blog/6900/webdriver-support-in-safari-10/</a></li>
</ol>
<h2 id="安装Selenium和chromedriver："><a href="#安装Selenium和chromedriver：" class="headerlink" title="安装Selenium和chromedriver："></a>安装Selenium和chromedriver：</h2><ol>
<li><p>安装Selenium，Selenium有很多语言的版本，有java、ruby、python等。我们下载python版本的就可以了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装<code>chromedriver</code>：下载完成后，放到不需要权限的纯英文目录下就可以了。</p>
</li>
</ol>
<h3 id="快速入门："><a href="#快速入门：" class="headerlink" title="快速入门："></a>快速入门：</h3><p>现在以一个简单的获取百度首页的例子来讲下<code>Selenium</code>和<code>chromedriver</code>如何快速入门：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line"><span class="comment"># chromedriver的绝对路径</span></span><br><span class="line">driver_path = <span class="string">r'D:\ProgramApp\chromedriver\chromedriver.exe'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个driver，并且指定chromedriver的路径</span></span><br><span class="line">driver = webdriver.Chrome(executable_path=driver_path)</span><br><span class="line"><span class="comment"># 请求网页</span></span><br><span class="line">driver.get(<span class="string">"https://www.baidu.com/"</span>)</span><br><span class="line"><span class="comment"># 通过page_source获取网页源代码</span></span><br><span class="line">print(driver.page_source)</span><br></pre></td></tr></table></figure>

<h3 id="selenium常用操作："><a href="#selenium常用操作：" class="headerlink" title="selenium常用操作："></a>selenium常用操作：</h3><p>更多教程请参考：<a href="http://selenium-python.readthedocs.io/installation.html#introduction" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/installation.html#introduction</a></p>
<h4 id="关闭页面："><a href="#关闭页面：" class="headerlink" title="关闭页面："></a>关闭页面：</h4><ol>
<li><code>driver.close()</code>：关闭当前页面。</li>
<li><code>driver.quit()</code>：退出整个浏览器。</li>
</ol>
<h4 id="定位元素："><a href="#定位元素：" class="headerlink" title="定位元素："></a>定位元素：</h4><ol>
<li><pre><code>find_element_by_id
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">根据id来查找某个元素。等价于：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"> submitTag = driver.find<span class="constructor">_element_by_id('<span class="params">su</span>')</span></span><br><span class="line"> submitTag1 = driver.find<span class="constructor">_element(By.ID,'<span class="params">su</span>')</span></span><br></pre></td></tr></table></figure></code></pre></li>
<li><pre><code>find_element_by_class_name
<figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">根据类名查找元素。 等价于：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"> submitTag = driver.find<span class="number">_</span>element<span class="number">_</span><span class="meta">by</span><span class="number">_</span><span class="keyword">class</span><span class="number">_n</span>ame(<span class="string">'su'</span>)</span><br><span class="line"> submitTag<span class="number">1</span> = driver.find<span class="number">_</span>element(By.CLASS<span class="number">_</span>NAME,<span class="string">'su'</span>)</span><br></pre></td></tr></table></figure></code></pre></li>
<li><pre><code>find_element_by_name
<figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">根据<span class="built_in">name</span>属性的值来查找元素。等价于：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"> submitTag = <span class="built_in">driver</span>.find_element_by_name(<span class="string">'email'</span>)</span><br><span class="line"> submitTag1 = <span class="built_in">driver</span>.find_element(By.<span class="built_in">NAME</span>,<span class="string">'email'</span>)</span><br></pre></td></tr></table></figure></code></pre></li>
<li><pre><code>find_element_by_tag_name
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">根据标签名来查找元素。等价于：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"> submitTag = driver.find<span class="constructor">_element_by_tag_name('<span class="params">div</span>')</span></span><br><span class="line"> submitTag1 = driver.find<span class="constructor">_element(By.TAG_NAME,'<span class="params">div</span>')</span></span><br></pre></td></tr></table></figure></code></pre></li>
<li><pre><code>find_element_by_xpath
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">根据xpath语法来获取元素。等价于：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"> submitTag = driver.find<span class="constructor">_element_by_xpath('<span class="operator">/</span><span class="operator">/</span><span class="params">div</span>')</span></span><br><span class="line"> submitTag1 = driver.find<span class="constructor">_element(By.XPATH,'<span class="operator">/</span><span class="operator">/</span><span class="params">div</span>')</span></span><br></pre></td></tr></table></figure></code></pre></li>
<li><p><code>find_element_by_css_selector</code>：根据css选择器选择元素。等价于：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">submitTag = driver.find_element_by_css_selector(<span class="string">'//div'</span>)</span><br><span class="line">submitTag1 = driver.find_element(By.CSS_SELECTOR,<span class="string">'//div'</span>)</span><br></pre></td></tr></table></figure>

<p>要注意，<code>find_element</code>是获取第一个满足条件的元素。<code>find_elements</code>是获取所有满足条件的元素。</p>
</li>
</ol>
<h4 id="操作表单元素："><a href="#操作表单元素：" class="headerlink" title="操作表单元素："></a>操作表单元素：</h4><ol>
<li><p>操作输入框：分为两步。第一步：找到这个元素。第二步：使用<code>send_keys(value)</code>，将数据填充进去。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputTag = driver.find_element_by_id(<span class="string">'kw'</span>)</span><br><span class="line">inputTag.send_keys(<span class="string">'python'</span>)</span><br></pre></td></tr></table></figure>

<p>使用<code>clear</code>方法可以清除输入框中的内容。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inputTag.clear()</span><br></pre></td></tr></table></figure>
</li>
<li><p>操作checkbox：因为要选中<code>checkbox</code>标签，在网页中是通过鼠标点击的。因此想要选中<code>checkbox</code>标签，那么先选中这个标签，然后执行<code>click</code>事件。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rememberTag = driver.find_element_by_name(<span class="string">"rememberMe"</span>)</span><br><span class="line">rememberTag.click()</span><br></pre></td></tr></table></figure>
</li>
<li><p>选择select：select元素不能直接点击。因为点击后还需要选中元素。这时候selenium就专门为select标签提供了一个类<code>selenium.webdriver.support.ui.Select</code>。将获取到的元素当成参数传到这个类中，创建这个对象。以后就可以使用这个对象进行选择了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> Select</span><br><span class="line"><span class="comment"># 选中这个标签，然后使用Select创建对象</span></span><br><span class="line">selectTag = Select(driver.find_element_by_name(<span class="string">"jumpMenu"</span>))</span><br><span class="line"><span class="comment"># 根据索引选择</span></span><br><span class="line">selectTag.select_by_index(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 根据值选择</span></span><br><span class="line">selectTag.select_by_value(<span class="string">"http://www.95yueba.com"</span>)</span><br><span class="line"><span class="comment"># 根据可视的文本选择</span></span><br><span class="line">selectTag.select_by_visible_text(<span class="string">"95秀客户端"</span>)</span><br><span class="line"><span class="comment"># 取消选中所有选项</span></span><br><span class="line">selectTag.deselect_all()</span><br></pre></td></tr></table></figure>
</li>
<li><p>操作按钮：操作按钮有很多种方式。比如单击、右击、双击等。这里讲一个最常用的。就是点击。直接调用<code>click</code>函数就可以了。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputTag = driver.find_element_by_id(<span class="string">'su'</span>)</span><br><span class="line">inputTag.click()</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="行为链："><a href="#行为链：" class="headerlink" title="行为链："></a>行为链：</h4><p>有时候在页面中的操作可能要有很多步，那么这时候可以使用鼠标行为链类<code>ActionChains</code>来完成。比如现在要将鼠标移动到某个元素上并执行点击事件。那么示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">inputTag = driver.find_element_by_id(<span class="string">'kw'</span>)</span><br><span class="line">submitTag = driver.find_element_by_id(<span class="string">'su'</span>)</span><br><span class="line"></span><br><span class="line">actions = ActionChains(driver)</span><br><span class="line">actions.move_to_element(inputTag)</span><br><span class="line">actions.send_keys_to_element(inputTag,<span class="string">'python'</span>)</span><br><span class="line">actions.move_to_element(submitTag)</span><br><span class="line">actions.click(submitTag)</span><br><span class="line">actions.perform()</span><br></pre></td></tr></table></figure>

<p>还有更多的鼠标相关的操作。</p>
<ul>
<li>click_and_hold(element)：点击但不松开鼠标。</li>
<li>context_click(element)：右键点击。</li>
<li>double_click(element)：双击。 更多方法请参考：<a href="http://selenium-python.readthedocs.io/api.html" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/api.html</a></li>
</ul>
<h4 id="Cookie操作："><a href="#Cookie操作：" class="headerlink" title="Cookie操作："></a>Cookie操作：</h4><ol>
<li><p>获取所有cookie</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> driver.get_cookies():</span><br><span class="line">    print(cookie)</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据cookie的key获取value：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value = driver.get_cookie(key)</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除所有的cookie：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">driver.delete_all_cookies()</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除某cookie</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">driver.delete_cookie(key)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="页面等待："><a href="#页面等待：" class="headerlink" title="页面等待："></a>页面等待：</h4><p>现在的网页越来越多采用了 Ajax 技术，这样程序便不能确定何时某个元素完全加载出来了。如果实际页面等待时间过长导致某个dom元素还没出来，但是你的代码直接使用了这个WebElement，那么就会抛出NullPointer的异常。为了解决这个问题。所以 Selenium 提供了两种等待方式：一种是隐式等待、一种是显式等待。</p>
<ol>
<li><p>隐式等待：调用<code>driver.implicitly_wait</code>。那么在获取不可用的元素之前，会先等待10秒中的时间。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Chrome(executable_path=driver_path)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 请求网页</span></span><br><span class="line">driver.get(<span class="string">"https://www.douban.com/"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>显示等待：显示等待是表明某个条件成立后才执行获取元素的操作。也可以在等待的时候指定一个最大的时间，如果超过这个时间那么就抛出一个异常。显示等待应该使用<code>selenium.webdriver.support.excepted_conditions</code>期望的条件和<code>selenium.webdriver.support.ui.WebDriverWait</code>来配合完成。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line">   </span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">"http://somedomain/url_that_delays_loading"</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    element = WebDriverWait(driver, <span class="number">10</span>).until(</span><br><span class="line">        EC.presence_of_element_located((By.ID, <span class="string">"myDynamicElement"</span>))</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    driver.quit()</span><br></pre></td></tr></table></figure>
</li>
<li><p>一些其他的等待条件：</p>
<ul>
<li><p>presence_of_element_located：某个元素已经加载完毕了。</p>
</li>
<li><p>presence_of_all_emement_located：网页中所有满足条件的元素都加载完毕了。</p>
</li>
<li><p>element_to_be_cliable：某个元素是可以点击了。</p>
<p>更多条件请参考：<a href="http://selenium-python.readthedocs.io/waits.html" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/waits.html</a></p>
</li>
</ul>
</li>
</ol>
<h4 id="切换页面："><a href="#切换页面：" class="headerlink" title="切换页面："></a>切换页面：</h4><p>有时候窗口中有很多子tab页面。这时候肯定是需要进行切换的。<code>selenium</code>提供了一个叫做<code>switch_to_window</code>来进行切换，具体切换到哪个页面，可以从<code>driver.window_handles</code>中找到。示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开一个新的页面</span></span><br><span class="line">self.driver.execute_script(<span class="string">"window.open('"</span>+url+<span class="string">"')"</span>)</span><br><span class="line"><span class="comment"># 切换到这个新的页面中</span></span><br><span class="line">self.driver.switch_to_window(self.driver.window_handles[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<h4 id="设置代理ip："><a href="#设置代理ip：" class="headerlink" title="设置代理ip："></a>设置代理ip：</h4><p>有时候频繁爬取一些网页。服务器发现你是爬虫后会封掉你的ip地址。这时候我们可以更改代理ip。更改代理ip，不同的浏览器有不同的实现方式。这里以<code>Chrome</code>浏览器为例来讲解：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">options = webdriver.ChromeOptions()</span><br><span class="line">options.add_argument(<span class="string">"--proxy-server=http://110.73.2.248:8123"</span>)</span><br><span class="line">driver_path = <span class="string">r"D:\ProgramApp\chromedriver\chromedriver.exe"</span></span><br><span class="line">driver = webdriver.Chrome(executable_path=driver_path,chrome_options=options)</span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">'http://httpbin.org/ip'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="WebElement元素："><a href="#WebElement元素：" class="headerlink" title="WebElement元素："></a><code>WebElement</code>元素：</h4><p><code>from selenium.webdriver.remote.webelement import WebElement</code>类是每个获取出来的元素的所属类。<br>有一些常用的属性：</p>
<ol>
<li>get_attribute：这个标签的某个属性的值。</li>
<li>screentshot：获取当前页面的截图。这个方法只能在<code>driver</code>上使用。<br><code>driver</code>的对象类，也是继承自<code>WebElement</code>。<br>更多请阅读相关源代码。</li>
</ol>
<h1 id="图形验证码识别技术："><a href="#图形验证码识别技术：" class="headerlink" title="图形验证码识别技术："></a>图形验证码识别技术：</h1><p>阻碍我们爬虫的。有时候正是在登录或者请求一些数据时候的图形验证码。因此这里我们讲解一种能将图片翻译成文字的技术。将图片翻译成文字一般被成为光学文字识别（Optical Character Recognition），简写为<code>OCR</code>。实现<code>OCR</code>的库不是很多，特别是开源的。因为这块存在一定的技术壁垒（需要大量的数据、算法、机器学习、深度学习知识等），并且如果做好了具有很高的商业价值。因此开源的比较少。这里介绍一个比较优秀的图像识别开源库：Tesseract。</p>
<h2 id="Tesseract："><a href="#Tesseract：" class="headerlink" title="Tesseract："></a>Tesseract：</h2><p>Tesseract是一个OCR库，目前由谷歌赞助。Tesseract是目前公认最优秀、最准确的开源OCR库。Tesseract具有很高的识别度，也具有很高的灵活性，他可以通过训练识别任何字体。</p>
<h3 id="安装："><a href="#安装：" class="headerlink" title="安装："></a>安装：</h3><h4 id="Windows系统："><a href="#Windows系统：" class="headerlink" title="Windows系统："></a>Windows系统：</h4><p>在以下链接下载可执行文件，然后一顿点击下一步安装即可（放在不需要权限的纯英文路径下）：<br><a href="https://github.com/tesseract-ocr/">https://github.com/tesseract-ocr/</a></p>
<h4 id="Linux系统："><a href="#Linux系统：" class="headerlink" title="Linux系统："></a>Linux系统：</h4><p>可以在以下链接下载源码自行编译。<br><a href="https://github.com/tesseract-ocr/tesseract/wiki/Compiling">https://github.com/tesseract-ocr/tesseract/wiki/Compiling</a><br>或者在<code>ubuntu</code>下通过以下命令进行安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install tesseract-ocr</span><br></pre></td></tr></table></figure>

<h4 id="Mac系统："><a href="#Mac系统：" class="headerlink" title="Mac系统："></a>Mac系统：</h4><p>用<code>Homebrew</code>即可方便安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install tesseract</span><br></pre></td></tr></table></figure>

<h4 id="设置环境变量："><a href="#设置环境变量：" class="headerlink" title="设置环境变量："></a>设置环境变量：</h4><p>安装完成后，如果想要在命令行中使用<code>Tesseract</code>，那么应该设置环境变量。<code>Mac</code>和<code>Linux</code>在安装的时候就默认已经设置好了。在<code>Windows</code>下把<code>tesseract.exe</code>所在的路径添加到<code>PATH</code>环境变量中。</p>
<p>还有一个环境变量需要设置的是，要把训练的数据文件路径也放到环境变量中。<br>在环境变量中，添加一个<code>TESSDATA_PREFIX=C:\path_to_tesseractdata\teseractdata</code>。</p>
<h3 id="在命令行中使用tesseract识别图像："><a href="#在命令行中使用tesseract识别图像：" class="headerlink" title="在命令行中使用tesseract识别图像："></a>在命令行中使用tesseract识别图像：</h3><p>如果想要在<code>cmd</code>下能够使用<code>tesseract</code>命令，那么需要把<code>tesseract.exe</code>所在的目录放到<code>PATH</code>环境变量中。然后使用命令：<code>tesseract 图片路径 文件路径</code>。<br>示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract a.png a</span><br></pre></td></tr></table></figure>

<p>那么就会识别出<code>a.png</code>中的图片，并且把文字写入到<code>a.txt</code>中。如果不想写入文件直接想显示在终端，那么不要加文件名就可以了。</p>
<h3 id="在代码中使用tesseract识别图像："><a href="#在代码中使用tesseract识别图像：" class="headerlink" title="在代码中使用tesseract识别图像："></a>在代码中使用tesseract识别图像：</h3><p>在<code>Python</code>代码中操作<code>tesseract</code>。需要安装一个库，叫做<code>pytesseract</code>。通过<code>pip</code>的方式即可安装：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> pytesseract</span><br></pre></td></tr></table></figure>

<p>并且，需要读取图片，需要借助一个第三方库叫做<code>PIL</code>。通过<code>pip list</code>看下是否安装。如果没有安装，通过<code>pip</code>的方式安装：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> PIL</span><br></pre></td></tr></table></figure>

<p>使用<code>pytesseract</code>将图片上的文字转换为文本文字的示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入pytesseract库</span></span><br><span class="line"><span class="keyword">import</span> pytesseract</span><br><span class="line"><span class="comment"># 导入Image库</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定tesseract.exe所在的路径</span></span><br><span class="line">pytesseract.pytesseract.tesseract_cmd = <span class="string">r'D:\ProgramApp\TesseractOCR\tesseract.exe'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开图片</span></span><br><span class="line">image = Image.open(<span class="string">"a.png"</span>)</span><br><span class="line"><span class="comment"># 调用image_to_string将图片转换为文字</span></span><br><span class="line">text = pytesseract.image_to_string(image)</span><br><span class="line">print(text)</span><br></pre></td></tr></table></figure>

<h2 id="用pytesseract处理拉勾网图形验证码："><a href="#用pytesseract处理拉勾网图形验证码：" class="headerlink" title="用pytesseract处理拉勾网图形验证码："></a>用<code>pytesseract</code>处理拉勾网图形验证码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytesseract</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pytesseract.pytesseract.tesseract_cmd = <span class="string">r"D:\ProgramApp\TesseractOCR\tesseract.exe"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    captchaUrl = <span class="string">"https://passport.lagou.com/vcode/create?from=register&amp;refresh=1513081451891"</span></span><br><span class="line">    request.urlretrieve(captchaUrl,<span class="string">'captcha.png'</span>)</span><br><span class="line">    image = Image.open(<span class="string">'captcha.png'</span>)</span><br><span class="line">    text = pytesseract.image_to_string(image,lang=<span class="string">'eng'</span>)</span><br><span class="line">    print(text)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Scrapy框架架构"><a href="#Scrapy框架架构" class="headerlink" title="Scrapy框架架构"></a>Scrapy框架架构</h1><h2 id="Scrapy框架介绍："><a href="#Scrapy框架介绍：" class="headerlink" title="Scrapy框架介绍："></a>Scrapy框架介绍：</h2><p>写一个爬虫，需要做很多的事情。比如：发送网络请求、数据解析、数据存储、反反爬虫机制（更换ip代理、设置请求头等）、异步请求等。这些工作如果每次都要自己从零开始写的话，比较浪费时间。因此<code>Scrapy</code>把一些基础的东西封装好了，在他上面写爬虫可以变的更加的高效（爬取效率和开发效率）。因此真正在公司里，一些上了量的爬虫，都是使用<code>Scrapy</code>框架来解决。</p>
<h2 id="Scrapy架构图："><a href="#Scrapy架构图：" class="headerlink" title="Scrapy架构图："></a>Scrapy架构图：</h2><ol>
<li>流程图（1）：<br><img src="../assets/scrapy_all.png" alt="img"></li>
<li>流程图（2）：<br><img src="../assets/884863172-5985e0b48edf9.png" alt="img"></li>
</ol>
<h2 id="Scrapy框架模块功能："><a href="#Scrapy框架模块功能：" class="headerlink" title="Scrapy框架模块功能："></a>Scrapy框架模块功能：</h2><ol>
<li><code>Scrapy Engine（引擎）</code>：<code>Scrapy</code>框架的核心部分。负责在<code>Spider</code>和<code>ItemPipeline</code>、<code>Downloader</code>、<code>Scheduler</code>中间通信、传递数据等。</li>
<li><code>Spider（爬虫）</code>：发送需要爬取的链接给引擎，最后引擎把其他模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。这个部分是我们开发者自己写的，因为要爬取哪些链接，页面中的哪些数据是我们需要的，都是由程序员自己决定。</li>
<li><code>Scheduler（调度器）</code>：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。</li>
<li><code>Downloader（下载器）</code>：负责接收引擎传过来的下载请求，然后去网络上下载对应的数据再交还给引擎。</li>
<li><code>Item Pipeline（管道）</code>：负责将<code>Spider（爬虫）</code>传递过来的数据进行保存。具体保存在哪里，应该看开发者自己的需求。</li>
<li><code>Downloader Middlewares（下载中间件）</code>：可以扩展下载器和引擎之间通信功能的中间件。</li>
<li><code>Spider Middlewares（Spider中间件）</code>：可以扩展引擎和爬虫之间通信功能的中间件。</li>
</ol>
<h1 id="Scrapy快速入门"><a href="#Scrapy快速入门" class="headerlink" title="Scrapy快速入门"></a>Scrapy快速入门</h1><h2 id="安装和文档：-1"><a href="#安装和文档：-1" class="headerlink" title="安装和文档："></a>安装和文档：</h2><ol>
<li>安装：通过<code>pip install scrapy</code>即可安装。</li>
<li>Scrapy官方文档：<a href="http://doc.scrapy.org/en/latest" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest</a></li>
<li>Scrapy中文文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html</a></li>
</ol>
<blockquote>
<p>注意：</p>
<ol>
<li>在<code>ubuntu</code>上安装<code>scrapy</code>之前，需要先安装以下依赖：<br><code>sudo apt-get install python3-dev build-essential python3-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code>，然后再通过<code>pip install scrapy</code>安装。</li>
<li>如果在<code>windows</code>系统下，提示这个错误<code>ModuleNotFoundError: No module named &#39;win32api&#39;</code>，那么使用以下命令可以解决：<code>pip install pypiwin32</code>。</li>
</ol>
</blockquote>
<h2 id="快速入门：-1"><a href="#快速入门：-1" class="headerlink" title="快速入门："></a>快速入门：</h2><h3 id="创建项目："><a href="#创建项目：" class="headerlink" title="创建项目："></a>创建项目：</h3><p>要使用<code>Scrapy</code>框架创建项目，需要通过命令来创建。首先进入到你想把这个项目存放的目录。然后使用以下命令创建：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject [项目名称]</span><br></pre></td></tr></table></figure>

<h3 id="目录结构介绍："><a href="#目录结构介绍：" class="headerlink" title="目录结构介绍："></a>目录结构介绍：</h3><p><img src="../assets/QQ%E6%88%AA%E5%9B%BE20171212213138.png" alt="img"><br>以下介绍下主要文件的作用：</p>
<ol>
<li>items.py：用来存放爬虫爬取下来数据的模型。</li>
<li>middlewares.py：用来存放各种中间件的文件。</li>
<li>pipelines.py：用来将<code>items</code>的模型存储到本地磁盘中。</li>
<li>settings.py：本爬虫的一些配置信息（比如请求头、多久发送一次请求、ip代理池等）。</li>
<li>scrapy.cfg：项目的配置文件。</li>
<li>spiders包：以后所有的爬虫，都是存放到这个里面。</li>
</ol>
<h3 id="使用Scrapy框架爬取糗事百科段子："><a href="#使用Scrapy框架爬取糗事百科段子：" class="headerlink" title="使用Scrapy框架爬取糗事百科段子："></a>使用Scrapy框架爬取糗事百科段子：</h3><h4 id="使用命令创建一个爬虫："><a href="#使用命令创建一个爬虫：" class="headerlink" title="使用命令创建一个爬虫："></a>使用命令创建一个爬虫：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy gensipder qsbk "qiushibaike.com"</span><br></pre></td></tr></table></figure>

<p>创建了一个名字叫做<code>qsbk</code>的爬虫，并且能爬取的网页只会限制在<code>qiushibaike.com</code>这个域名下。</p>
<h4 id="爬虫代码解析："><a href="#爬虫代码解析：" class="headerlink" title="爬虫代码解析："></a>爬虫代码解析：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QsbkSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'qsbk'</span></span><br><span class="line">    allowed_domains = [<span class="string">'qiushibaike.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://qiushibaike.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>其实这些代码我们完全可以自己手动去写，而不用命令。只不过是不用命令，自己写这些代码比较麻烦。<br>要创建一个Spider，那么必须自定义一个类，继承自<code>scrapy.Spider</code>，然后在这个类中定义三个属性和一个方法。</p>
<ol>
<li>name：这个爬虫的名字，名字必须是唯一的。</li>
<li>allow_domains：允许的域名。爬虫只会爬取这个域名下的网页，其他不是这个域名下的网页会被自动忽略。</li>
<li>start_urls：爬虫从这个变量中的url开始。</li>
<li>parse：引擎会把下载器下载回来的数据扔给爬虫解析，爬虫再把数据传给这个<code>parse</code>方法。这个是个固定的写法。这个方法的作用有两个，第一个是提取想要的数据。第二个是生成下一个请求的url。</li>
</ol>
<h4 id="修改settings-py代码："><a href="#修改settings-py代码：" class="headerlink" title="修改settings.py代码："></a>修改<code>settings.py</code>代码：</h4><p>在做一个爬虫之前，一定要记得修改<code>setttings.py</code>中的设置。两个地方是强烈建议设置的。</p>
<ol>
<li><code>ROBOTSTXT_OBEY</code>设置为False。默认是True。即遵守机器协议，那么在爬虫的时候，scrapy首先去找robots.txt文件，如果没有找到。则直接停止爬取。</li>
<li><code>DEFAULT_REQUEST_HEADERS</code>添加<code>User-Agent</code>。这个也是告诉服务器，我这个请求是一个正常的请求，不是一个爬虫。</li>
</ol>
<h4 id="完成的爬虫代码："><a href="#完成的爬虫代码：" class="headerlink" title="完成的爬虫代码："></a>完成的爬虫代码：</h4><ol>
<li><p>爬虫部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> abcspider.items <span class="keyword">import</span> QsbkItem</span><br><span class="line">   </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QsbkSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'qsbk'</span></span><br><span class="line">    allowed_domains = [<span class="string">'qiushibaike.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://www.qiushibaike.com/text/'</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        outerbox = response.xpath(<span class="string">"//div[@id='content-left']/div"</span>)</span><br><span class="line">        items = []</span><br><span class="line">        <span class="keyword">for</span> box <span class="keyword">in</span> outerbox:</span><br><span class="line">            author = box.xpath(<span class="string">".//div[contains(@class,'author')]//h2/text()"</span>).extract_first().strip()</span><br><span class="line">            content = box.xpath(<span class="string">".//div[@class='content']/span/text()"</span>).extract_first().strip()</span><br><span class="line">            item = QsbkItem()</span><br><span class="line">            item[<span class="string">"author"</span>] = author</span><br><span class="line">            item[<span class="string">"content"</span>] = content</span><br><span class="line">            items.append(item)</span><br><span class="line">        <span class="keyword">return</span> items</span><br></pre></td></tr></table></figure>
</li>
<li><p>items.py部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QsbkItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>
</li>
<li><p>pipeline部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">   </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AbcspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">   </span><br><span class="line">        self.items = []</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.items.append(dict(item))</span><br><span class="line">        print(<span class="string">"="</span>*<span class="number">40</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'qsbk.json'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            json.dump(self.items,fp,ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="运行scrapy项目："><a href="#运行scrapy项目：" class="headerlink" title="运行scrapy项目："></a>运行scrapy项目：</h4><p>运行scrapy项目。需要在终端，进入项目所在的路径，然后<code>scrapy crawl [爬虫名字]</code>即可运行指定的爬虫。如果不想每次都在命令行中运行，那么可以把这个命令写在一个文件中。以后就在pycharm中执行运行这个文件就可以了。比如现在新创建一个文件叫做<code>start.py</code>，然后在这个文件中填入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">"scrapy crawl qsbk"</span>.split())</span><br></pre></td></tr></table></figure>

<h1 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h1><p>在上一个糗事百科的爬虫案例中。我们是自己在解析完整个页面后获取下一页的url，然后重新发送一个请求。有时候我们想要这样做，只要满足某个条件的url，都给我进行爬取。那么这时候我们就可以通过<code>CrawlSpider</code>来帮我们完成了。<code>CrawlSpider</code>继承自<code>Spider</code>，只不过是在之前的基础之上增加了新的功能，可以定义爬取的url的规则，以后scrapy碰到满足条件的url都进行爬取，而不用手动的<code>yield Request</code>。</p>
<h2 id="CrawlSpider爬虫："><a href="#CrawlSpider爬虫：" class="headerlink" title="CrawlSpider爬虫："></a>CrawlSpider爬虫：</h2><h3 id="创建CrawlSpider爬虫："><a href="#创建CrawlSpider爬虫：" class="headerlink" title="创建CrawlSpider爬虫："></a>创建CrawlSpider爬虫：</h3><p>之前创建爬虫的方式是通过<code>scrapy genspider [爬虫名字] [域名]</code>的方式创建的。如果想要创建<code>CrawlSpider</code>爬虫，那么应该通过以下命令创建：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -c crawl [爬虫名字] [域名]</span><br></pre></td></tr></table></figure>

<h3 id="LinkExtractors链接提取器："><a href="#LinkExtractors链接提取器：" class="headerlink" title="LinkExtractors链接提取器："></a>LinkExtractors链接提取器：</h3><p>使用<code>LinkExtractors</code>可以不用程序员自己提取想要的url，然后发送请求。这些工作都可以交给<code>LinkExtractors</code>，他会在所有爬的页面中找到满足规则的<code>url</code>，实现自动的爬取。以下对<code>LinkExtractors</code>类做一个简单的介绍：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">linkextractors</span>.<span class="title">LinkExtractor</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    allow = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    allow_domains = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny_domains = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    deny_extensions = None,</span></span></span><br><span class="line"><span class="class"><span class="params">    restrict_xpaths = <span class="params">()</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    tags = <span class="params">(<span class="string">'a'</span>,<span class="string">'area'</span>)</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    attrs = <span class="params">(<span class="string">'href'</span>)</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    canonicalize = True,</span></span></span><br><span class="line"><span class="class"><span class="params">    unique = True,</span></span></span><br><span class="line"><span class="class"><span class="params">    process_value = None</span></span></span><br><span class="line"><span class="class"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>

<p>主要参数讲解：</p>
<ul>
<li>allow：允许的url。所有满足这个正则表达式的url都会被提取。</li>
<li>deny：禁止的url。所有满足这个正则表达式的url都不会被提取。</li>
<li>allow_domains：允许的域名。只有在这个里面指定的域名的url才会被提取。</li>
<li>deny_domains：禁止的域名。所有在这个里面指定的域名的url都不会被提取。</li>
<li>restrict_xpaths：严格的xpath。和allow共同过滤链接。</li>
</ul>
<h3 id="Rule规则类："><a href="#Rule规则类：" class="headerlink" title="Rule规则类："></a>Rule规则类：</h3><p>定义爬虫的规则类。以下对这个类做一个简单的介绍：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">spiders</span>.<span class="title">Rule</span><span class="params">(</span></span></span><br><span class="line"><span class="class"><span class="params">    link_extractor, </span></span></span><br><span class="line"><span class="class"><span class="params">    callback = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    cb_kwargs = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    follow = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    process_links = None, </span></span></span><br><span class="line"><span class="class"><span class="params">    process_request = None</span></span></span><br><span class="line"><span class="class"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>

<p>主要参数讲解：</p>
<ul>
<li>link_extractor：一个<code>LinkExtractor</code>对象，用于定义爬取规则。</li>
<li>callback：满足这个规则的url，应该要执行哪个回调函数。因为<code>CrawlSpider</code>使用了<code>parse</code>作为回调函数，因此不要覆盖<code>parse</code>作为回调函数自己的回调函数。</li>
<li>follow：指定根据该规则从response中提取的链接是否需要跟进。</li>
<li>process_links：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接。</li>
</ul>
<h1 id="Scrapy-Shell"><a href="#Scrapy-Shell" class="headerlink" title="Scrapy Shell"></a>Scrapy Shell</h1><p>我们想要在爬虫中使用xpath、beautifulsoup、正则表达式、css选择器等来提取想要的数据。但是因为<code>scrapy</code>是一个比较重的框架。每次运行起来都要等待一段时间。因此要去验证我们写的提取规则是否正确，是一个比较麻烦的事情。因此<code>Scrapy</code>提供了一个shell，用来方便的测试规则。当然也不仅仅局限于这一个功能。</p>
<h2 id="打开Scrapy-Shell："><a href="#打开Scrapy-Shell：" class="headerlink" title="打开Scrapy Shell："></a>打开Scrapy Shell：</h2><p>打开cmd终端，进入到<code>Scrapy</code>项目所在的目录，然后进入到<code>scrapy</code>框架所在的虚拟环境中，输入命令<code>scrapy shell [链接]</code>。就会进入到scrapy的shell环境中。在这个环境中，你可以跟在爬虫的<code>parse</code>方法中一样使用了。 </p>
<h1 id="redis教程："><a href="#redis教程：" class="headerlink" title="redis教程："></a>redis教程：</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><code>redis</code>是一种支持分布式的<code>nosql</code>数据库,他的数据是保存在内存中，同时<code>redis</code>可以定时把内存数据同步到磁盘，即可以将数据持久化，并且他比<code>memcached</code>支持更多的数据结构(<code>string</code>,<code>list列表[队列和栈]</code>,<code>set[集合]</code>,<code>sorted set[有序集合]</code>,<code>hash(hash表)</code>)。相关参考文档：<a href="http://redisdoc.com/index.html" target="_blank" rel="noopener">http://redisdoc.com/index.html</a></p>
<h2 id="redis使用场景："><a href="#redis使用场景：" class="headerlink" title="redis使用场景："></a>redis使用场景：</h2><ol>
<li>登录会话存储：存储在<code>redis</code>中，与<code>memcached</code>相比，数据不会丢失。</li>
<li>排行版/计数器：比如一些秀场类的项目，经常会有一些前多少名的主播排名。还有一些文章阅读量的技术，或者新浪微博的点赞数等。</li>
<li>作为消息队列：比如<code>celery</code>就是使用<code>redis</code>作为中间人。</li>
<li>当前在线人数：还是之前的秀场例子，会显示当前系统有多少在线人数。</li>
<li>一些常用的数据缓存：比如我们的<code>BBS</code>论坛，板块不会经常变化的，但是每次访问首页都要从<code>mysql</code>中获取，可以在<code>redis</code>中缓存起来，不用每次请求数据库。</li>
<li>把前200篇文章缓存或者评论缓存：一般用户浏览网站，只会浏览前面一部分文章或者评论，那么可以把前面200篇文章和对应的评论缓存起来。用户访问超过的，就访问数据库，并且以后文章超过200篇，则把之前的文章删除。</li>
<li>好友关系：微博的好友关系使用<code>redis</code>实现。</li>
<li>发布和订阅功能：可以用来做聊天软件。</li>
</ol>
<h2 id="redis和memcached的比较："><a href="#redis和memcached的比较：" class="headerlink" title="redis和memcached的比较："></a><code>redis</code>和<code>memcached</code>的比较：</h2><table>
<thead>
<tr>
<th></th>
<th>memcached</th>
<th>redis</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>纯内存数据库</td>
<td>内存磁盘同步数据库</td>
</tr>
<tr>
<td>数据类型</td>
<td>在定义value时就要固定数据类型</td>
<td>不需要</td>
</tr>
<tr>
<td>虚拟内存</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>过期策略</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>存储数据安全</td>
<td>不支持</td>
<td>可以将数据同步到dump.db中</td>
</tr>
<tr>
<td>灾难恢复</td>
<td>不支持</td>
<td>可以将磁盘中的数据恢复到内存中</td>
</tr>
<tr>
<td>分布式</td>
<td>支持</td>
<td>主从同步</td>
</tr>
<tr>
<td>订阅与发布</td>
<td>不支持</td>
<td>支持</td>
</tr>
</tbody></table>
<h2 id="redis在ubuntu系统中的安装与启动"><a href="#redis在ubuntu系统中的安装与启动" class="headerlink" title="redis在ubuntu系统中的安装与启动"></a><code>redis</code>在<code>ubuntu</code>系统中的安装与启动</h2><ol>
<li><p>安装：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="keyword">get</span> install redis-<span class="keyword">server</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>卸载：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="builtin-name">get</span> purge --auto-<span class="builtin-name">remove</span> redis-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动：<code>redis</code>安装后，默认会自动启动，可以通过以下命令查看：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ps</span> aux|<span class="keyword">grep</span> redis</span><br></pre></td></tr></table></figure>

<p>如果想自己手动启动，可以通过以下命令进行启动：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo<span class="built_in"> service </span>redis-server start</span><br></pre></td></tr></table></figure>
</li>
<li><p>停止：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo<span class="built_in"> service </span>redis-server stop</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="redis在windows系统中的安装与启动："><a href="#redis在windows系统中的安装与启动：" class="headerlink" title="redis在windows系统中的安装与启动："></a>redis在windows系统中的安装与启动：</h2><ol>
<li>下载：redis官方是不支持windows操作系统的。但是微软的开源部门将redis移植到了windows上。因此下载地址不是在redis官网上。而是在github上：<a href="https://github.com/MicrosoftArchive/redis/releases。">https://github.com/MicrosoftArchive/redis/releases。</a></li>
<li>安装：点击一顿下一步安装就可以了。</li>
<li>运行：进入到<code>redis</code>安装所在的路径然后执行<code>redis-server.exe redis.windows.conf</code>就可以运行了。</li>
<li>连接：<code>redis</code>和<code>mysql</code>以及<code>mongo</code>是一样的，都提供了一个客户端进行连接。输入命令<code>redis-cli</code>（前提是redis安装路径已经加入到环境变量中了）就可以连接到<code>redis</code>服务器了。</li>
</ol>
<h2 id="其他机器访问本机redis服务器："><a href="#其他机器访问本机redis服务器：" class="headerlink" title="其他机器访问本机redis服务器："></a>其他机器访问本机redis服务器：</h2><p>想要让其他机器访问本机的redis服务器。那么要修改redis.conf的配置文件，将bind改成<code>bind [自己的ip地址或者0.0.0.0]</code>，其他机器才能访问。<br><strong>注意：bind绑定的是本机网卡的ip地址，而不是想让其他机器连接的ip地址。如果有多块网卡，那么可以绑定多个网卡的ip地址。如果绑定到额是0.0.0.0，那么意味着其他机器可以通过本机所有的ip地址进行访问。</strong></p>
<h2 id="对redis的操作"><a href="#对redis的操作" class="headerlink" title="对redis的操作"></a>对<code>redis</code>的操作</h2><p>对<code>redis</code>的操作可以用两种方式，第一种方式采用<code>redis-cli</code>，第二种方式采用编程语言，比如<code>Python</code>、<code>PHP</code>和<code>JAVA</code>等。</p>
<ol>
<li><p>使用<code>redis-cli</code>对<code>redis</code>进行字符串操作：</p>
</li>
<li><p>启动<code>redis</code>：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo<span class="built_in"> service </span>redis-server start</span><br></pre></td></tr></table></figure>
</li>
<li><p>连接上</p>
<figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-<span class="keyword">server</span></span><br></pre></td></tr></table></figure>

<p>：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">redis-cli</span> <span class="selector-tag">-h</span> <span class="selector-attr">[ip]</span> <span class="selector-tag">-p</span> <span class="selector-attr">[端口]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>添加：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> key <span class="comment">value</span></span><br><span class="line">如：</span><br><span class="line"><span class="keyword">set</span> <span class="comment">username xiaotuo</span></span><br></pre></td></tr></table></figure>

<p>将字符串值<code>value</code>关联到<code>key</code>。如果<code>key</code>已经持有其他值，<code>set</code>命令就覆写旧值，无视其类型。并且默认的过期时间是永久，即永远不会过期。</p>
</li>
<li><p>删除：</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">del</span> <span class="built_in">key</span></span><br><span class="line">如：</span><br><span class="line"><span class="built_in">del</span> username</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置过期时间：</p>
<figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">expire</span> <span class="variable">key</span> <span class="function"><span class="title">timeout</span>(单位为秒)</span></span><br></pre></td></tr></table></figure>

<p>也可以在设置值的时候，一同指定过期时间：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">key</span> <span class="keyword">value</span> EX <span class="keyword">timeout</span></span><br><span class="line">或：</span><br><span class="line">setex <span class="keyword">key</span> <span class="keyword">timeout</span> <span class="keyword">value</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>查看过期时间：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ttl</span> <span class="string">key</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">ttl</span> <span class="string">username</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>查看当前<code>redis</code>中的所有<code>key</code>：</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">keys</span> *</span><br></pre></td></tr></table></figure>
</li>
<li><p>列表操作：</p>
<ul>
<li><p>在列表左边添加元素：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lpush <span class="built_in">key</span> <span class="built_in">value</span></span><br></pre></td></tr></table></figure>

<p>将值<code>value</code>插入到列表<code>key</code>的表头。如果<code>key</code>不存在，一个空列表会被创建并执行<code>lpush</code>操作。当<code>key</code>存在但不是列表类型时，将返回一个错误。</p>
</li>
<li><p>在列表右边添加元素：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpush <span class="built_in">key</span> <span class="built_in">value</span></span><br></pre></td></tr></table></figure>

<p>将值value插入到列表key的表尾。如果key不存在，一个空列表会被创建并执行RPUSH操作。当key存在但不是列表类型时，返回一个错误。</p>
</li>
<li><p>查看列表中的元素：</p>
<figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lrange</span> key start stop</span><br></pre></td></tr></table></figure>

<p>返回列表<code>key</code>中指定区间内的元素，区间以偏移量<code>start</code>和<code>stop</code>指定,如果要左边的第一个到最后的一个<code>lrange key 0 -1</code>。</p>
</li>
<li><p>移除列表中的元素：</p>
<ul>
<li><p>移除并返回列表</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">key</span></span><br></pre></td></tr></table></figure>

<p>的头元素：</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">lpop key</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>移除并返回列表的尾元素：</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">rpop key</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>移除并返回列表<code>key</code>的中间元素：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lrem <span class="built_in">key</span> <span class="built_in">count</span> <span class="built_in">value</span></span><br></pre></td></tr></table></figure>

<p>将删除<code>key</code>这个列表中，<code>count</code>个值为<code>value</code>的元素。</p>
</li>
</ul>
</li>
<li><p>指定返回第几个元素：</p>
<figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">lindex</span> key index</span><br></pre></td></tr></table></figure>

<p>将返回<code>key</code>这个列表中，索引为<code>index</code>的这个元素。</p>
</li>
<li><p>获取列表中的元素个数：</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">llen </span>key</span><br><span class="line">如：</span><br><span class="line"><span class="keyword">llen </span>languages</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除指定的元素：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lrem <span class="built_in">key</span> <span class="built_in">count</span> <span class="built_in">value</span></span><br><span class="line">如：</span><br><span class="line">lrem languages <span class="number">0</span> php</span><br></pre></td></tr></table></figure>

<p>根据参数 count 的值，移除列表中与参数 value 相等的元素。<code>count</code>的值可以是以下几种：</p>
<ul>
<li>count &gt; 0：从表头开始向表尾搜索，移除与<code>value</code>相等的元素，数量为<code>count</code>。</li>
<li>count &lt; 0：从表尾开始向表头搜索，移除与 <code>value</code>相等的元素，数量为<code>count</code>的绝对值。</li>
<li>count = 0：移除表中所有与<code>value</code> 相等的值。</li>
</ul>
</li>
</ul>
</li>
<li><p><code>set</code>集合的操作：</p>
<ul>
<li><p>添加元素：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">sadd</span></span> <span class="keyword">set</span> value1 <span class="comment">value2....</span></span><br><span class="line">如：</span><br><span class="line">sadd <span class="comment">team xiaotuo datuo</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>查看元素：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">smembers <span class="keyword">set</span></span><br><span class="line">如：</span><br><span class="line">smembers <span class="comment">team</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>移除元素：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">srem</span></span> <span class="keyword">set</span> member...</span><br><span class="line">如：</span><br><span class="line">srem <span class="comment">team xiaotuo datuo</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>查看集合中的元素个数：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scard <span class="keyword">set</span></span><br><span class="line">如：</span><br><span class="line">scard <span class="comment">team1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取多个集合的交集：</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sinter <span class="keyword">set</span>1 <span class="keyword">set</span>2</span><br><span class="line">如：</span><br><span class="line">sinter team1 team2</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取多个集合的并集：</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sunion <span class="keyword">set</span>1 <span class="keyword">set</span>2</span><br><span class="line">如：</span><br><span class="line">sunion team1 team2</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取多个集合的差集：</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sdiff set<span class="number">1</span> set<span class="number">2</span></span><br><span class="line">如：</span><br><span class="line">sdiff tea<span class="name">m1</span> tea<span class="name">m2</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><code>hash</code>哈希操作：</p>
<ul>
<li><p>添加一个新值：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">hset</span> key <span class="meta">field</span> value</span><br><span class="line">如：</span><br><span class="line"><span class="symbol">hset</span> website <span class="keyword">baidu </span><span class="keyword">baidu.com</span></span><br></pre></td></tr></table></figure>

<p>将哈希表<code>key</code>中的域<code>field</code>的值设为<code>value</code>。<br>如果<code>key</code>不存在，一个新的哈希表被创建并进行 <code>HSET</code>操作。如果域 <code>field</code>已经存在于哈希表中，旧值将被覆盖。</p>
</li>
<li><p>获取哈希中的<code>field</code>对应的值：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hget</span> <span class="string">key field</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hget</span> <span class="string">website baidu</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>删除<code>field</code>中的某个<code>field</code>：</p>
<figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hdel</span> <span class="built_in">key</span> field</span><br><span class="line">如：</span><br><span class="line"><span class="built_in">hdel</span> website baidu</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取某个哈希中所有的<code>field</code>和<code>value</code>：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hgetall</span> <span class="string">key</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hgetall</span> <span class="string">website</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取某个哈希中所有的<code>field</code>：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hkeys</span> <span class="string">key</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hkeys</span> <span class="string">website</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取某个哈希中所有的值：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hvals</span> <span class="string">key</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hvals</span> <span class="string">website</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>判断哈希中是否存在某个<code>field</code>：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hexists</span> <span class="string">key field</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hexists</span> <span class="string">website baidu</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取哈希中总共的键值对：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hlen</span> <span class="string">field</span></span><br><span class="line"><span class="attr">如：</span></span><br><span class="line"><span class="attr">hlen</span> <span class="string">website</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>事务操作：Redis事务可以一次执行多个命令，事务具有以下特征：</p>
<ul>
<li><p>隔离操作：事务中的所有命令都会序列化、按顺序地执行，不会被其他命令打扰。</p>
</li>
<li><p>原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>
</li>
<li><p>开启一个事务：</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">multi</span></span><br></pre></td></tr></table></figure>

<p>以后执行的所有命令，都在这个事务中执行的。</p>
</li>
<li><p>执行事务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span></span><br></pre></td></tr></table></figure>

<p>会将在<code>multi</code>和<code>exec</code>中的操作一并提交。</p>
</li>
<li><p>取消事务：</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">discard</span></span><br></pre></td></tr></table></figure>

<p>会将<code>multi</code>后的所有命令取消。</p>
</li>
<li><p>监视一个或者多个<code>key</code>：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">watch</span></span> key...</span><br></pre></td></tr></table></figure>

<p>监视一个(或多个)key，如果在事务执行之前这个(或这些) key被其他命令所改动，那么事务将被打断。</p>
</li>
<li><p>取消所有<code>key</code>的监视：</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">unwatch</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>发布/订阅操作：</p>
<ul>
<li><p>给某个频道发布消息：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">publish channel <span class="keyword">message</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>订阅某个频道的消息：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">subscribe </span>channel</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ol>
<h1 id="Scrapy-Redis分布式爬虫组件"><a href="#Scrapy-Redis分布式爬虫组件" class="headerlink" title="Scrapy-Redis分布式爬虫组件"></a>Scrapy-Redis分布式爬虫组件</h1><p><code>Scrapy</code>是一个框架，他本身是不支持分布式的。如果我们想要做分布式的爬虫，就需要借助一个组件叫做<code>Scrapy-Redis</code>，这个组件正是利用了<code>Redis</code>可以分布式的功能，集成到<code>Scrapy</code>框架中，使得爬虫可以进行分布式。可以充分的利用资源（多个ip、更多带宽、同步爬取）来提高爬虫的爬行效率。</p>
<h2 id="分布式爬虫的优点："><a href="#分布式爬虫的优点：" class="headerlink" title="分布式爬虫的优点："></a>分布式爬虫的优点：</h2><ol>
<li>可以充分利用多台机器的带宽。</li>
<li>可以充分利用多台机器的ip地址。</li>
<li>多台机器做，爬取效率更高。</li>
</ol>
<h2 id="分布式爬虫必须要解决的问题："><a href="#分布式爬虫必须要解决的问题：" class="headerlink" title="分布式爬虫必须要解决的问题："></a>分布式爬虫必须要解决的问题：</h2><ol>
<li>分布式爬虫是好几台机器在同时运行，如何保证不同的机器爬取页面的时候不会出现重复爬取的问题。</li>
<li>同样，分布式爬虫在不同的机器上运行，在把数据爬完后如何保证保存在同一个地方。</li>
</ol>
<h2 id="安装：-1"><a href="#安装：-1" class="headerlink" title="安装："></a>安装：</h2><p>通过<code>pip install scrapy-redis</code>即可安装。</p>
<h2 id="Scrapy-Redis架构："><a href="#Scrapy-Redis架构：" class="headerlink" title="Scrapy-Redis架构："></a>Scrapy-Redis架构：</h2><p>Scrapy架构图：<br><img src="../assets/scrapy_all.png" alt="img"></p>
<p>Scrapy-Redis架构图：<br><img src="../assets/scrapy-redis.png" alt="img"></p>
<p>分布式爬虫架构图：<br><img src="../assets/fenbushi.png" alt="img"></p>
<p>以上两个图片对比我们可以发现。<code>Item Pipeline</code>在接收到数据后发送给了<code>Redis</code>、<code>Scheduler</code>调度器调度数据也是从<code>Redis</code>中来的、并且其实数据去重也是在<code>Redis</code>中做的。</p>
<h2 id="编写Scrapy-Redis分布式爬虫："><a href="#编写Scrapy-Redis分布式爬虫：" class="headerlink" title="编写Scrapy-Redis分布式爬虫："></a>编写Scrapy-Redis分布式爬虫：</h2><p>要将一个<code>Scrapy</code>项目变成一个<code>Scrapy-redis</code>项目只需修改以下三点就可以了：</p>
<ol>
<li>将爬虫的类从<code>scrapy.Spider</code>变成<code>scrapy_redis.spiders.RedisSpider</code>；或者是从<code>scrapy.CrawlSpider</code>变成<code>scrapy_redis.spiders.RedisCrawlSpider</code>。</li>
<li>将爬虫中的<code>start_urls</code>删掉。增加一个<code>redis_key=&quot;xxx&quot;</code>。这个<code>redis_key</code>是为了以后在<code>redis</code>中控制爬虫启动的。爬虫的第一个url，就是在redis中通过这个发送出去的。</li>
<li>在配置文件中增加如下配置：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scrapy-Redis相关配置</span></span><br><span class="line"><span class="comment"># 确保request存储到redis中</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保所有爬虫共享相同的去重指纹</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置redis为item pipeline</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在redis中保持scrapy-redis用到的队列，不会清理redis中的队列，从而可以实现暂停和恢复的功能。</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置连接redis信息</span></span><br><span class="line">REDIS_HOST = <span class="string">'127.0.0.1'</span></span><br><span class="line">REDIS_PORT = <span class="number">6379</span></span><br></pre></td></tr></table></figure>

<ol>
<li>运行爬虫：<ol>
<li>在爬虫服务器上。进入爬虫文件所在的路径，然后输入命令：<code>scrapy runspider [爬虫名字]</code>。</li>
<li>在<code>Redis</code>服务器上，推入一个开始的url链接：<code>redis-cli&gt; lpush [redis_key] start_url</code>开始爬取。</li>
</ol>
</li>
</ol>

      
    </div>
    
    
    
    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
      
    </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat.jpg" alt="李义 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/aipay.png" alt="李义 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
    
    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 网络爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/06/02/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8BPandas/" rel="next" title="Python数据分析三剑客之Pandas">
                <i class="fa fa-chevron-left"></i> Python数据分析三剑客之Pandas
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/06/29/java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="prev" title="java数据结构">
                java数据结构 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/touxiang.jpg"
                alt="李义" />
            
              <p class="site-author-name" itemprop="name">李义</p>
              <p class="site-description motion-element" itemprop="description">这里写描述</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#网络爬虫"><span class="nav-number">1.</span> <span class="nav-text">网络爬虫</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是网络爬虫："><span class="nav-number">2.</span> <span class="nav-text">什么是网络爬虫：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#http协议和Chrome抓包工具"><span class="nav-number">3.</span> <span class="nav-text">http协议和Chrome抓包工具</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是http和https协议："><span class="nav-number">3.1.</span> <span class="nav-text">什么是http和https协议：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#浏览器请求"><span class="nav-number">3.2.</span> <span class="nav-text">浏览器请求</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是URL"><span class="nav-number">3.2.1.</span> <span class="nav-text">什么是URL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常用的请求方法"><span class="nav-number">3.2.2.</span> <span class="nav-text">常用的请求方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#请求头常见参数"><span class="nav-number">3.2.3.</span> <span class="nav-text">请求头常见参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见响应状态码"><span class="nav-number">3.2.4.</span> <span class="nav-text">常见响应状态码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chrome抓包工具："><span class="nav-number">3.3.</span> <span class="nav-text">Chrome抓包工具：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#urllib库"><span class="nav-number">4.</span> <span class="nav-text">urllib库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#urlopen"><span class="nav-number">4.1.</span> <span class="nav-text">urlopen</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urlretrieve函数"><span class="nav-number">4.2.</span> <span class="nav-text">urlretrieve函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urlencode函数"><span class="nav-number">4.3.</span> <span class="nav-text">urlencode函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#urlparse和urlsplit"><span class="nav-number">4.4.</span> <span class="nav-text">urlparse和urlsplit</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#request-Request类"><span class="nav-number">4.5.</span> <span class="nav-text">request.Request类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ProxyHandler处理器（代理设置）"><span class="nav-number">4.6.</span> <span class="nav-text">ProxyHandler处理器（代理设置）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是cookie"><span class="nav-number">5.</span> <span class="nav-text">什么是cookie</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用cookielib库和HTTPCookieProcessor模拟登录"><span class="nav-number">5.1.</span> <span class="nav-text">使用cookielib库和HTTPCookieProcessor模拟登录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#http-cookiejar模块"><span class="nav-number">5.2.</span> <span class="nav-text">http.cookiejar模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#保存cookie到本地"><span class="nav-number">5.2.0.1.</span> <span class="nav-text">保存cookie到本地</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#从本地加载cookie"><span class="nav-number">5.2.0.2.</span> <span class="nav-text">从本地加载cookie</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#requests库"><span class="nav-number">6.</span> <span class="nav-text">requests库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#发送GET请求"><span class="nav-number">6.1.</span> <span class="nav-text">发送GET请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#发送POST请求"><span class="nav-number">6.2.</span> <span class="nav-text">发送POST请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用代理"><span class="nav-number">6.3.</span> <span class="nav-text">使用代理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cookie"><span class="nav-number">6.4.</span> <span class="nav-text">cookie</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#session"><span class="nav-number">6.5.</span> <span class="nav-text">session</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#XPath语法和lxml模块"><span class="nav-number">7.</span> <span class="nav-text">XPath语法和lxml模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是XPath？"><span class="nav-number">7.1.</span> <span class="nav-text">什么是XPath？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XPath开发工具"><span class="nav-number">7.2.</span> <span class="nav-text">XPath开发工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XPath语法"><span class="nav-number">7.3.</span> <span class="nav-text">XPath语法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#选取节点"><span class="nav-number">7.3.1.</span> <span class="nav-text">选取节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#谓语"><span class="nav-number">7.3.2.</span> <span class="nav-text">谓语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#通配符"><span class="nav-number">7.3.3.</span> <span class="nav-text">通配符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选取多个路径："><span class="nav-number">7.3.4.</span> <span class="nav-text">选取多个路径：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lxml库"><span class="nav-number">7.4.</span> <span class="nav-text">lxml库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本使用："><span class="nav-number">7.4.1.</span> <span class="nav-text">基本使用：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从文件中读取html代码："><span class="nav-number">7.4.2.</span> <span class="nav-text">从文件中读取html代码：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在lxml中使用XPath语法："><span class="nav-number">7.4.3.</span> <span class="nav-text">在lxml中使用XPath语法：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#爬取德州学院官网上的校报图片"><span class="nav-number">7.5.</span> <span class="nav-text">爬取德州学院官网上的校报图片</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BeautifulSoup4库"><span class="nav-number">8.</span> <span class="nav-text">BeautifulSoup4库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装和文档："><span class="nav-number">8.1.</span> <span class="nav-text">安装和文档：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#几大解析工具对比："><span class="nav-number">8.2.</span> <span class="nav-text">几大解析工具对比：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#简单使用："><span class="nav-number">8.3.</span> <span class="nav-text">简单使用：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四个常用的对象："><span class="nav-number">8.4.</span> <span class="nav-text">四个常用的对象：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Tag："><span class="nav-number">8.4.1.</span> <span class="nav-text">1. Tag：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-NavigableString："><span class="nav-number">8.4.2.</span> <span class="nav-text">2. NavigableString：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-BeautifulSoup："><span class="nav-number">8.4.3.</span> <span class="nav-text">3. BeautifulSoup：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Comment："><span class="nav-number">8.4.4.</span> <span class="nav-text">4. Comment：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#遍历文档树："><span class="nav-number">8.5.</span> <span class="nav-text">遍历文档树：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-contents和children："><span class="nav-number">8.5.1.</span> <span class="nav-text">1. contents和children：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-strings-和-stripped-strings"><span class="nav-number">8.5.2.</span> <span class="nav-text">2. strings 和 stripped_strings</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#搜索文档树："><span class="nav-number">8.6.</span> <span class="nav-text">搜索文档树：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-find和find-all方法："><span class="nav-number">8.6.1.</span> <span class="nav-text">1. find和find_all方法：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-select方法："><span class="nav-number">8.6.2.</span> <span class="nav-text">2. select方法：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（1）通过标签名查找："><span class="nav-number">8.6.2.1.</span> <span class="nav-text">（1）通过标签名查找：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（2）通过类名查找："><span class="nav-number">8.6.2.2.</span> <span class="nav-text">（2）通过类名查找：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（3）通过id查找："><span class="nav-number">8.6.2.3.</span> <span class="nav-text">（3）通过id查找：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（4）组合查找："><span class="nav-number">8.6.2.4.</span> <span class="nav-text">（4）组合查找：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（5）通过属性查找："><span class="nav-number">8.6.2.5.</span> <span class="nav-text">（5）通过属性查找：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（6）获取内容"><span class="nav-number">8.6.2.6.</span> <span class="nav-text">（6）获取内容</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则表达式和re模块："><span class="nav-number">9.</span> <span class="nav-text">正则表达式和re模块：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是正则表达式："><span class="nav-number">9.1.</span> <span class="nav-text">什么是正则表达式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一个段子："><span class="nav-number">9.2.</span> <span class="nav-text">一个段子：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则表达式常用匹配规则："><span class="nav-number">9.3.</span> <span class="nav-text">正则表达式常用匹配规则：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#匹配某个字符串："><span class="nav-number">9.3.1.</span> <span class="nav-text">匹配某个字符串：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#点（-）匹配任意的字符："><span class="nav-number">9.3.2.</span> <span class="nav-text">点（.）匹配任意的字符：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#d匹配任意的数字："><span class="nav-number">9.3.3.</span> <span class="nav-text">\d匹配任意的数字：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#D匹配任意的非数字："><span class="nav-number">9.3.4.</span> <span class="nav-text">\D匹配任意的非数字：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#s匹配的是空白字符（包括：-n，-t，-r和空格）："><span class="nav-number">9.3.5.</span> <span class="nav-text">\s匹配的是空白字符（包括：\n，\t，\r和空格）：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#w匹配的是a-z和A-Z以及数字和下划线："><span class="nav-number">9.3.6.</span> <span class="nav-text">\w匹配的是a-z和A-Z以及数字和下划线：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#W匹配的是和-w相反的："><span class="nav-number">9.3.7.</span> <span class="nav-text">\W匹配的是和\w相反的：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#组合的方式，只要满足中括号中的某一项都算匹配成功："><span class="nav-number">9.3.8.</span> <span class="nav-text">[]组合的方式，只要满足中括号中的某一项都算匹配成功：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#匹配多个字符："><span class="nav-number">9.3.9.</span> <span class="nav-text">匹配多个字符：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小案例："><span class="nav-number">9.3.10.</span> <span class="nav-text">小案例：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#（脱字号）：表示以…开始："><span class="nav-number">9.3.11.</span> <span class="nav-text">^（脱字号）：表示以…开始：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#：表示以…结束："><span class="nav-number">9.3.12.</span> <span class="nav-text">$：表示以…结束：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#：匹配多个表达式或者字符串："><span class="nav-number">9.3.13.</span> <span class="nav-text">|：匹配多个表达式或者字符串：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贪婪模式和非贪婪模式："><span class="nav-number">9.3.14.</span> <span class="nav-text">贪婪模式和非贪婪模式：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#案例：匹配0-100之间的数字："><span class="nav-number">9.3.15.</span> <span class="nav-text">案例：匹配0-100之间的数字：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转义字符和原生字符串："><span class="nav-number">9.3.16.</span> <span class="nav-text">转义字符和原生字符串：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#re模块中常用函数："><span class="nav-number">9.4.</span> <span class="nav-text">re模块中常用函数：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#match："><span class="nav-number">9.4.1.</span> <span class="nav-text">match：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#search："><span class="nav-number">9.4.2.</span> <span class="nav-text">search：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分组："><span class="nav-number">9.4.3.</span> <span class="nav-text">分组：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#findall："><span class="nav-number">9.4.4.</span> <span class="nav-text">findall：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sub："><span class="nav-number">9.4.5.</span> <span class="nav-text">sub：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#split："><span class="nav-number">9.4.6.</span> <span class="nav-text">split：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#compile："><span class="nav-number">9.4.7.</span> <span class="nav-text">compile：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#json文件处理："><span class="nav-number">10.</span> <span class="nav-text">json文件处理：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是json："><span class="nav-number">10.1.</span> <span class="nav-text">什么是json：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#JSON支持数据格式："><span class="nav-number">10.2.</span> <span class="nav-text">JSON支持数据格式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#字典和列表转JSON："><span class="nav-number">10.3.</span> <span class="nav-text">字典和列表转JSON：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#将json数据直接dump到文件中："><span class="nav-number">10.3.1.</span> <span class="nav-text">将json数据直接dump到文件中：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#将一个json字符串load成Python对象："><span class="nav-number">10.4.</span> <span class="nav-text">将一个json字符串load成Python对象：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#直接从文件中读取json："><span class="nav-number">10.4.1.</span> <span class="nav-text">直接从文件中读取json：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#csv文件处理"><span class="nav-number">11.</span> <span class="nav-text">csv文件处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#读取csv文件："><span class="nav-number">11.1.</span> <span class="nav-text">读取csv文件：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#写入数据到csv文件："><span class="nav-number">11.2.</span> <span class="nav-text">写入数据到csv文件：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MySQL数据库操作"><span class="nav-number">12.</span> <span class="nav-text">MySQL数据库操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装mysql："><span class="nav-number">12.1.</span> <span class="nav-text">安装mysql：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#navicat："><span class="nav-number">12.2.</span> <span class="nav-text">navicat：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装驱动程序："><span class="nav-number">12.3.</span> <span class="nav-text">安装驱动程序：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据库连接："><span class="nav-number">12.4.</span> <span class="nav-text">数据库连接：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#插入数据："><span class="nav-number">12.5.</span> <span class="nav-text">插入数据：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查找数据："><span class="nav-number">12.6.</span> <span class="nav-text">查找数据：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#删除数据："><span class="nav-number">12.7.</span> <span class="nav-text">删除数据：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更新数据："><span class="nav-number">12.8.</span> <span class="nav-text">更新数据：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多线程爬虫"><span class="nav-number">13.</span> <span class="nav-text">多线程爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#多线程介绍："><span class="nav-number">13.1.</span> <span class="nav-text">多线程介绍：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#threading模块介绍："><span class="nav-number">13.2.</span> <span class="nav-text">threading模块介绍：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#查看线程数："><span class="nav-number">13.2.1.</span> <span class="nav-text">查看线程数：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查看当前线程的名字："><span class="nav-number">13.2.2.</span> <span class="nav-text">查看当前线程的名字：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#继承自threading-Thread类："><span class="nav-number">13.2.3.</span> <span class="nav-text">继承自threading.Thread类：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多线程共享全局变量的问题："><span class="nav-number">13.2.4.</span> <span class="nav-text">多线程共享全局变量的问题：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#锁机制："><span class="nav-number">13.2.5.</span> <span class="nav-text">锁机制：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lock版本生产者和消费者模式："><span class="nav-number">13.3.</span> <span class="nav-text">Lock版本生产者和消费者模式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Condition版的生产者与消费者模式："><span class="nav-number">13.4.</span> <span class="nav-text">Condition版的生产者与消费者模式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Queue线程安全队列："><span class="nav-number">13.5.</span> <span class="nav-text">Queue线程安全队列：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用生产者与消费者模式多线程下载表情包："><span class="nav-number">13.6.</span> <span class="nav-text">使用生产者与消费者模式多线程下载表情包：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GIL全局解释器锁："><span class="nav-number">13.7.</span> <span class="nav-text">GIL全局解释器锁：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多线程下载百思不得姐段子作业："><span class="nav-number">13.8.</span> <span class="nav-text">多线程下载百思不得姐段子作业：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#动态网页数据抓取"><span class="nav-number">14.</span> <span class="nav-text">动态网页数据抓取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是AJAX："><span class="nav-number">14.1.</span> <span class="nav-text">什么是AJAX：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取ajax数据的方式："><span class="nav-number">14.2.</span> <span class="nav-text">获取ajax数据的方式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Selenium-chromedriver获取动态数据："><span class="nav-number">14.3.</span> <span class="nav-text">Selenium+chromedriver获取动态数据：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装Selenium和chromedriver："><span class="nav-number">14.4.</span> <span class="nav-text">安装Selenium和chromedriver：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#快速入门："><span class="nav-number">14.4.1.</span> <span class="nav-text">快速入门：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#selenium常用操作："><span class="nav-number">14.4.2.</span> <span class="nav-text">selenium常用操作：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#关闭页面："><span class="nav-number">14.4.2.1.</span> <span class="nav-text">关闭页面：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定位元素："><span class="nav-number">14.4.2.2.</span> <span class="nav-text">定位元素：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#操作表单元素："><span class="nav-number">14.4.2.3.</span> <span class="nav-text">操作表单元素：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#行为链："><span class="nav-number">14.4.2.4.</span> <span class="nav-text">行为链：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cookie操作："><span class="nav-number">14.4.2.5.</span> <span class="nav-text">Cookie操作：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#页面等待："><span class="nav-number">14.4.2.6.</span> <span class="nav-text">页面等待：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切换页面："><span class="nav-number">14.4.2.7.</span> <span class="nav-text">切换页面：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置代理ip："><span class="nav-number">14.4.2.8.</span> <span class="nav-text">设置代理ip：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WebElement元素："><span class="nav-number">14.4.2.9.</span> <span class="nav-text">WebElement元素：</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图形验证码识别技术："><span class="nav-number">15.</span> <span class="nav-text">图形验证码识别技术：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tesseract："><span class="nav-number">15.1.</span> <span class="nav-text">Tesseract：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装："><span class="nav-number">15.1.1.</span> <span class="nav-text">安装：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Windows系统："><span class="nav-number">15.1.1.1.</span> <span class="nav-text">Windows系统：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Linux系统："><span class="nav-number">15.1.1.2.</span> <span class="nav-text">Linux系统：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mac系统："><span class="nav-number">15.1.1.3.</span> <span class="nav-text">Mac系统：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置环境变量："><span class="nav-number">15.1.1.4.</span> <span class="nav-text">设置环境变量：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在命令行中使用tesseract识别图像："><span class="nav-number">15.1.2.</span> <span class="nav-text">在命令行中使用tesseract识别图像：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在代码中使用tesseract识别图像："><span class="nav-number">15.1.3.</span> <span class="nav-text">在代码中使用tesseract识别图像：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用pytesseract处理拉勾网图形验证码："><span class="nav-number">15.2.</span> <span class="nav-text">用pytesseract处理拉勾网图形验证码：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy框架架构"><span class="nav-number">16.</span> <span class="nav-text">Scrapy框架架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy框架介绍："><span class="nav-number">16.1.</span> <span class="nav-text">Scrapy框架介绍：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy架构图："><span class="nav-number">16.2.</span> <span class="nav-text">Scrapy架构图：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy框架模块功能："><span class="nav-number">16.3.</span> <span class="nav-text">Scrapy框架模块功能：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy快速入门"><span class="nav-number">17.</span> <span class="nav-text">Scrapy快速入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装和文档：-1"><span class="nav-number">17.1.</span> <span class="nav-text">安装和文档：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#快速入门：-1"><span class="nav-number">17.2.</span> <span class="nav-text">快速入门：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建项目："><span class="nav-number">17.2.1.</span> <span class="nav-text">创建项目：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#目录结构介绍："><span class="nav-number">17.2.2.</span> <span class="nav-text">目录结构介绍：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用Scrapy框架爬取糗事百科段子："><span class="nav-number">17.2.3.</span> <span class="nav-text">使用Scrapy框架爬取糗事百科段子：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用命令创建一个爬虫："><span class="nav-number">17.2.3.1.</span> <span class="nav-text">使用命令创建一个爬虫：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#爬虫代码解析："><span class="nav-number">17.2.3.2.</span> <span class="nav-text">爬虫代码解析：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修改settings-py代码："><span class="nav-number">17.2.3.3.</span> <span class="nav-text">修改settings.py代码：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#完成的爬虫代码："><span class="nav-number">17.2.3.4.</span> <span class="nav-text">完成的爬虫代码：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#运行scrapy项目："><span class="nav-number">17.2.3.5.</span> <span class="nav-text">运行scrapy项目：</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CrawlSpider"><span class="nav-number">18.</span> <span class="nav-text">CrawlSpider</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CrawlSpider爬虫："><span class="nav-number">18.1.</span> <span class="nav-text">CrawlSpider爬虫：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建CrawlSpider爬虫："><span class="nav-number">18.1.1.</span> <span class="nav-text">创建CrawlSpider爬虫：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LinkExtractors链接提取器："><span class="nav-number">18.1.2.</span> <span class="nav-text">LinkExtractors链接提取器：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rule规则类："><span class="nav-number">18.1.3.</span> <span class="nav-text">Rule规则类：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy-Shell"><span class="nav-number">19.</span> <span class="nav-text">Scrapy Shell</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#打开Scrapy-Shell："><span class="nav-number">19.1.</span> <span class="nav-text">打开Scrapy Shell：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#redis教程："><span class="nav-number">20.</span> <span class="nav-text">redis教程：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#概述"><span class="nav-number">20.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis使用场景："><span class="nav-number">20.2.</span> <span class="nav-text">redis使用场景：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis和memcached的比较："><span class="nav-number">20.3.</span> <span class="nav-text">redis和memcached的比较：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis在ubuntu系统中的安装与启动"><span class="nav-number">20.4.</span> <span class="nav-text">redis在ubuntu系统中的安装与启动</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis在windows系统中的安装与启动："><span class="nav-number">20.5.</span> <span class="nav-text">redis在windows系统中的安装与启动：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他机器访问本机redis服务器："><span class="nav-number">20.6.</span> <span class="nav-text">其他机器访问本机redis服务器：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对redis的操作"><span class="nav-number">20.7.</span> <span class="nav-text">对redis的操作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy-Redis分布式爬虫组件"><span class="nav-number">21.</span> <span class="nav-text">Scrapy-Redis分布式爬虫组件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式爬虫的优点："><span class="nav-number">21.1.</span> <span class="nav-text">分布式爬虫的优点：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式爬虫必须要解决的问题："><span class="nav-number">21.2.</span> <span class="nav-text">分布式爬虫必须要解决的问题：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装：-1"><span class="nav-number">21.3.</span> <span class="nav-text">安装：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy-Redis架构："><span class="nav-number">21.4.</span> <span class="nav-text">Scrapy-Redis架构：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编写Scrapy-Redis分布式爬虫："><span class="nav-number">21.5.</span> <span class="nav-text">编写Scrapy-Redis分布式爬虫：</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">李义</span>

  
</div>
<!--


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>

-->


<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">symbols_count_time.count_total：</span>
    
  <span title="Site words total count">
     147.1k字 </span>
    <!--<span title="symbols_count_time.count_total">455k</span>-->
  
  <div class="theme-info">
    <div class="powered-by"></div>
    <span class="post-count">博客全站共147.1k字</span>
  </div>
  <!-- 新增访客统计代码 -->

<div class="busuanzi-count">
    <script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="site-uv">
      <i class="fa fa-user"></i>
      访问用户： <span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人
    </span>
    <div class="powered-by"></div>
    <span class="site-uv">
      <i class="fa fa-eye"></i>
      访问次数： <span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次
    </span>
    <!-- 博客字数统计 -->
    <span class="site-pv">
      <i class="fa fa-pencil"></i>
      博客全站共： <span class="post-count">147.1k</span> 字
    </span>
</div>
<!-- 新增访客统计代码 END-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("HHo5ARpd4p1yPoBL3xYEgcNV-gzGzoHsz", "2SnHYdpQzjgbCuF8NdQlghh");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

  
  <!-- 代码块复制功能 -->
  <script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
  <script type="text/javascript" src="/js/src/clipboard-use.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body>
</html>
